{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkpcHsV8RWHA"
      },
      "source": [
        "## Задание 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAQBOJRARev7"
      },
      "source": [
        "**Написать теггер на данных с руским языком**\n",
        "1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации  \n",
        "2. написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
        "3. сравнить все реализованные методы сделать выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_16J0ER8WOJx"
      },
      "source": [
        "## загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPRx8Cu_RDY1",
        "outputId": "3be2188e-e158-4e6f-f5d8-ffe73fad3ed7"
      },
      "source": [
        "!pip install pyconll"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyconll\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/4c/edf12b4b211f8a0f7f85a52ed4b50cd453ac96e9b751427e0296eb7ae42a/pyconll-3.1.0-py3-none-any.whl\n",
            "Installing collected packages: pyconll\n",
            "Successfully installed pyconll-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wgL-33mWUyZ"
      },
      "source": [
        "import pyconll"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXxwW9NzW570"
      },
      "source": [
        "!mkdir datasets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpwgA3svWiRw",
        "outputId": "45b88e58-e93a-4eae-a9db-506ce9ad79d3"
      },
      "source": [
        "!wget -O ./datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
        "!wget -O ./datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-16 14:09:55--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81039282 (77M) [text/plain]\n",
            "Saving to: ‘./datasets/ru_syntagrus-ud-train.conllu’\n",
            "\n",
            "./datasets/ru_synta 100%[===================>]  77.28M   206MB/s    in 0.4s    \n",
            "\n",
            "2021-07-16 14:09:58 (206 MB/s) - ‘./datasets/ru_syntagrus-ud-train.conllu’ saved [81039282/81039282]\n",
            "\n",
            "--2021-07-16 14:09:58--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10902738 (10M) [text/plain]\n",
            "Saving to: ‘./datasets/ru_syntagrus-ud-dev.conllu’\n",
            "\n",
            "./datasets/ru_synta 100%[===================>]  10.40M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-07-16 14:09:59 (122 MB/s) - ‘./datasets/ru_syntagrus-ud-dev.conllu’ saved [10902738/10902738]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oymo30RBWjjl"
      },
      "source": [
        "full_train = pyconll.load_from_file('datasets/ru_syntagrus-ud-train.conllu')\n",
        "full_test = pyconll.load_from_file('datasets/ru_syntagrus-ud-dev.conllu')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBzFe82cXGNK",
        "outputId": "7121ce04-ee8f-4def-b977-0d2ad36d88a0"
      },
      "source": [
        "for sent in full_train[:2]:\n",
        "    for token in sent:\n",
        "        print(token.form, token.upos)\n",
        "    print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Анкета NOUN\n",
            ". PUNCT\n",
            "\n",
            "Начальник NOUN\n",
            "областного ADJ\n",
            "управления NOUN\n",
            "связи NOUN\n",
            "Семен PROPN\n",
            "Еремеевич PROPN\n",
            "был AUX\n",
            "человек NOUN\n",
            "простой ADJ\n",
            ", PUNCT\n",
            "приходил VERB\n",
            "на ADP\n",
            "работу NOUN\n",
            "всегда ADV\n",
            "вовремя ADV\n",
            ", PUNCT\n",
            "здоровался VERB\n",
            "с ADP\n",
            "секретаршей NOUN\n",
            "за ADP\n",
            "руку NOUN\n",
            "и CCONJ\n",
            "иногда ADV\n",
            "даже PART\n",
            "писал VERB\n",
            "в ADP\n",
            "стенгазету NOUN\n",
            "заметки NOUN\n",
            "под ADP\n",
            "псевдонимом NOUN\n",
            "\" PUNCT\n",
            "Муха NOUN\n",
            "\" PUNCT\n",
            ". PUNCT\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wHKvFmn3wSI"
      },
      "source": [
        "fdata_train = []\n",
        "for sent in full_train[:]:\n",
        "    fdata_train.append([(token.form.lower(), token.upos) for token in sent])\n",
        "    \n",
        "fdata_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_test.append([(token.form.lower(), token.upos) for token in sent])\n",
        "    \n",
        "fdata_sent_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_sent_test.append([token.form.lower() for token in sent])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ1GT0n03FL-"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlXcPPkS4UtR"
      },
      "source": [
        "from nltk.tag import DefaultTagger\n",
        "from nltk.tag import UnigramTagger\n",
        "from nltk.tag import BigramTagger, TrigramTagger"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "dj4tV8ytXTry",
        "outputId": "38a75477-da61-4c0a-aab4-01bc2a03895f"
      },
      "source": [
        "unigram_tagger = UnigramTagger(fdata_train)\n",
        "display(unigram_tagger.tag(fdata_sent_test[100]), unigram_tagger.evaluate(fdata_test))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('это', 'PRON'),\n",
              " ('сочинение', 'NOUN'),\n",
              " ('известно', 'ADJ'),\n",
              " ('во', 'ADP'),\n",
              " ('многих', 'NUM'),\n",
              " ('вариантах', 'NOUN'),\n",
              " ('(', 'PUNCT'),\n",
              " ('самые', 'ADJ'),\n",
              " ('ранние', 'ADJ'),\n",
              " ('из', 'ADP'),\n",
              " ('них', 'PRON'),\n",
              " ('почти', 'ADV'),\n",
              " ('на', 'ADP'),\n",
              " ('сто', 'NUM'),\n",
              " ('лет', 'NOUN'),\n",
              " ('старше', 'ADJ'),\n",
              " (')', 'PUNCT'),\n",
              " ('и', 'CCONJ'),\n",
              " ('восходит', 'VERB'),\n",
              " ('к', 'ADP'),\n",
              " ('ещё', 'ADV'),\n",
              " ('более', 'ADV'),\n",
              " ('древним', 'ADJ'),\n",
              " ('рукописям', None),\n",
              " ('xvi', 'NUM'),\n",
              " ('в', 'ADP'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.8819634010716814"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "DskURpG942x8",
        "outputId": "5b3339b1-7447-4a3c-894f-c350bb34e1fd"
      },
      "source": [
        "bigram_tagger = BigramTagger(fdata_train, backoff=unigram_tagger)\n",
        "display(bigram_tagger.tag(fdata_sent_test[100]), bigram_tagger.evaluate(fdata_test))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('это', 'PRON'),\n",
              " ('сочинение', 'NOUN'),\n",
              " ('известно', 'ADJ'),\n",
              " ('во', 'ADP'),\n",
              " ('многих', 'NUM'),\n",
              " ('вариантах', 'NOUN'),\n",
              " ('(', 'PUNCT'),\n",
              " ('самые', 'ADJ'),\n",
              " ('ранние', 'ADJ'),\n",
              " ('из', 'ADP'),\n",
              " ('них', 'PRON'),\n",
              " ('почти', 'ADV'),\n",
              " ('на', 'ADP'),\n",
              " ('сто', 'NUM'),\n",
              " ('лет', 'NOUN'),\n",
              " ('старше', 'ADJ'),\n",
              " (')', 'PUNCT'),\n",
              " ('и', 'CCONJ'),\n",
              " ('восходит', 'VERB'),\n",
              " ('к', 'ADP'),\n",
              " ('ещё', 'ADV'),\n",
              " ('более', 'ADV'),\n",
              " ('древним', 'ADJ'),\n",
              " ('рукописям', None),\n",
              " ('xvi', 'NUM'),\n",
              " ('в', 'ADP'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.8882907019849695"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "biXWBA_T5D4y",
        "outputId": "da5703f9-e8b2-4eb4-8525-7caa5bf20ae7"
      },
      "source": [
        "trigram_tagger = TrigramTagger(fdata_train, backoff=bigram_tagger)\n",
        "display(trigram_tagger.tag(fdata_sent_test[100]), trigram_tagger.evaluate(fdata_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('это', 'PRON'),\n",
              " ('сочинение', 'NOUN'),\n",
              " ('известно', 'ADJ'),\n",
              " ('во', 'ADP'),\n",
              " ('многих', 'NUM'),\n",
              " ('вариантах', 'NOUN'),\n",
              " ('(', 'PUNCT'),\n",
              " ('самые', 'ADJ'),\n",
              " ('ранние', 'ADJ'),\n",
              " ('из', 'ADP'),\n",
              " ('них', 'PRON'),\n",
              " ('почти', 'ADV'),\n",
              " ('на', 'ADP'),\n",
              " ('сто', 'NUM'),\n",
              " ('лет', 'NOUN'),\n",
              " ('старше', 'ADJ'),\n",
              " (')', 'PUNCT'),\n",
              " ('и', 'CCONJ'),\n",
              " ('восходит', 'VERB'),\n",
              " ('к', 'ADP'),\n",
              " ('ещё', 'ADV'),\n",
              " ('более', 'ADV'),\n",
              " ('древним', 'ADJ'),\n",
              " ('рукописям', None),\n",
              " ('xvi', 'NUM'),\n",
              " ('в', 'ADP'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.8874566103865467"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fx6vNgC5Nl5",
        "outputId": "74a778d1-9279-4df4-8a83-38b6049c8296"
      },
      "source": [
        "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
        "    for cls in tagger_classes:\n",
        "        backoff = cls(train_sents, backoff=backoff)\n",
        "    return backoff\n",
        "\n",
        "\n",
        "backoff = DefaultTagger('NN') \n",
        "tag = backoff_tagger(fdata_train,  \n",
        "                     [UnigramTagger, BigramTagger, TrigramTagger],  \n",
        "                     backoff = backoff) \n",
        "  \n",
        "tag.evaluate(fdata_test) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8868668486502881"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pHbWXI0822V"
      },
      "source": [
        "2. написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8SfNcNh82ab"
      },
      "source": [
        "train_tok = []\n",
        "train_label = []\n",
        "for sent in fdata_train[:]:\n",
        "    for tok in sent:\n",
        "        train_tok.append(tok[0])\n",
        "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
        "        \n",
        "test_tok = []\n",
        "test_label = []\n",
        "for sent in fdata_test[:]:\n",
        "    for tok in sent:\n",
        "        test_tok.append(tok[0])\n",
        "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPG8TZGR9UEH"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiZpX8BX9mvF"
      },
      "source": [
        "le = LabelEncoder()\n",
        "train_enc_labels = le.fit_transform(train_label)\n",
        "test_enc_labels = le.transform(test_label)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_a5525e9ty5"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 3), analyzer='char', max_features=30)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIr0IX6m939v"
      },
      "source": [
        "X_train = vectorizer.fit_transform(train_tok)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X222SUnN-B7O"
      },
      "source": [
        "X_test = vectorizer.transform(test_tok)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwQDugXi-JIT",
        "outputId": "4d64a939-fe3c-4d17-942a-193c439b311f"
      },
      "source": [
        "lr = LogisticRegression(random_state=0, max_iter=10)\n",
        "lr.fit(X_train, train_enc_labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=10,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU3ucYUg-RhH"
      },
      "source": [
        "pred = lr.predict(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgMtqkX9-VmG",
        "outputId": "fface981-9f40-4e33-eecc-43bdc54e0f8d"
      },
      "source": [
        "accuracy_score(test_enc_labels, pred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6128972466552084"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pix-nzy-t7A"
      },
      "source": [
        "word_vectorizer = CountVectorizer(ngram_range=(1,5), analyzer='word', max_features=30)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt7eZxZJ-x9z"
      },
      "source": [
        "X_train_word = word_vectorizer.fit_transform(train_tok)\n",
        "X_test_word = word_vectorizer.transform(test_tok)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HQOBykg-67i",
        "outputId": "8c846c13-d09a-47b2-f3aa-f8b447690cf8"
      },
      "source": [
        "lr1 = LogisticRegression(random_state=0, max_iter=10)\n",
        "lr1.fit(X_train_word, train_enc_labels)\n",
        "pred1 = lr1.predict(X_test_word)\n",
        "accuracy_score(test_enc_labels, pred1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3118070299598962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw8Kjjse_q8z"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 9), analyzer='char')\n",
        "X_train_c = vectorizer.fit_transform(train_tok)\n",
        "X_test_c = vectorizer.transform(test_tok)\n",
        "word_vectorizer = CountVectorizer(ngram_range=(1,9), analyzer='word')\n",
        "X_train_w = word_vectorizer.fit_transform(train_tok)\n",
        "X_test_w = word_vectorizer.transform(test_tok)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBYBJo4CAD4t"
      },
      "source": [
        "from scipy.sparse import hstack\n",
        "X_train = hstack((X_train_c, X_train_w))\n",
        "X_test = hstack((X_test_c, X_test_w))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGhGq_WNAM7I",
        "outputId": "e5c21bc6-5e9d-40c4-dbdd-e610c6dcb572"
      },
      "source": [
        "lr = LogisticRegression(random_state=0, max_iter=25)\n",
        "lr.fit(X_train, train_enc_labels)\n",
        "pred = lr.predict(X_test)\n",
        "accuracy_score(test_enc_labels, pred)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9121255012974758"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cINqgGpKXURp"
      },
      "source": [
        "# Задание 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUOg4C8sZNpw"
      },
      "source": [
        "данные http://www.labinform.ru/pub/named_entities/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzi6ApNLZg6X"
      },
      "source": [
        "**Проверить насколько хорошо работает NER**\n",
        "\n",
        "1. взять нер из nltk\n",
        "2. проверить deeppavlov\n",
        "3. написать свой нер попробовать разные подходы \n",
        "  - передаём в сетку токен и его соседей\n",
        "  - передаём в сетку только токен\n",
        "4. сделать выводы по вашим экспериментам какой из подходов успешнее справляется"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP1LgaNUtaOz"
      },
      "source": [
        "при обучении своего нера незабудьте разделить выборку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg6tcss2Zhp9",
        "outputId": "4414bc36-e647-498c-e6bc-9991ce8b6141"
      },
      "source": [
        "!pip install corus"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting corus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/a3/e680679c669b0118271ac7246549c75a7088ab0e6696a3561408a3f9b50d/corus-0.9.0-py3-none-any.whl (83kB)\n",
            "\r\u001b[K     |████                            | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 20kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 30kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.8MB/s \n",
            "\u001b[?25hInstalling collected packages: corus\n",
            "Successfully installed corus-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrc5ocDkaS1e"
      },
      "source": [
        "import corus"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPVv6lhT3ftA",
        "outputId": "aab80b15-0756-4cbc-a50d-fd51145bc5c5"
      },
      "source": [
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-17 10:35:59--  http://www.labinform.ru/pub/named_entities/collection5.zip\n",
            "Resolving www.labinform.ru (www.labinform.ru)... 80.240.100.4\n",
            "Connecting to www.labinform.ru (www.labinform.ru)|80.240.100.4|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1899530 (1.8M) [application/zip]\n",
            "Saving to: ‘collection5.zip’\n",
            "\n",
            "collection5.zip     100%[===================>]   1.81M   223KB/s    in 9.6s    \n",
            "\n",
            "2021-07-17 10:36:10 (194 KB/s) - ‘collection5.zip’ saved [1899530/1899530]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtLK4z9CH2Ph",
        "outputId": "34e12033-93fe-481f-f5c2-a4800bea8856"
      },
      "source": [
        "!unzip collection5.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  collection5.zip\n",
            "   creating: Collection5/\n",
            "  inflating: Collection5/001.ann     \n",
            "  inflating: Collection5/001.txt     \n",
            "  inflating: Collection5/002.ann     \n",
            "  inflating: Collection5/002.txt     \n",
            "  inflating: Collection5/003.ann     \n",
            "  inflating: Collection5/003.txt     \n",
            "  inflating: Collection5/004.ann     \n",
            "  inflating: Collection5/004.txt     \n",
            "  inflating: Collection5/005.ann     \n",
            "  inflating: Collection5/005.txt     \n",
            "  inflating: Collection5/006.ann     \n",
            "  inflating: Collection5/006.txt     \n",
            "  inflating: Collection5/007.ann     \n",
            "  inflating: Collection5/007.txt     \n",
            "  inflating: Collection5/008.ann     \n",
            "  inflating: Collection5/008.txt     \n",
            "  inflating: Collection5/009.ann     \n",
            "  inflating: Collection5/009.txt     \n",
            "  inflating: Collection5/010.ann     \n",
            "  inflating: Collection5/010.txt     \n",
            "  inflating: Collection5/011.ann     \n",
            "  inflating: Collection5/011.txt     \n",
            "  inflating: Collection5/012.ann     \n",
            "  inflating: Collection5/012.txt     \n",
            "  inflating: Collection5/013.ann     \n",
            "  inflating: Collection5/013.txt     \n",
            "  inflating: Collection5/014.ann     \n",
            "  inflating: Collection5/014.txt     \n",
            "  inflating: Collection5/015 (!).ann  \n",
            "  inflating: Collection5/015 (!).txt  \n",
            "  inflating: Collection5/016.ann     \n",
            "  inflating: Collection5/016.txt     \n",
            "  inflating: Collection5/017.ann     \n",
            "  inflating: Collection5/017.txt     \n",
            "  inflating: Collection5/018.ann     \n",
            "  inflating: Collection5/018.txt     \n",
            "  inflating: Collection5/019.ann     \n",
            "  inflating: Collection5/019.txt     \n",
            "  inflating: Collection5/020.ann     \n",
            "  inflating: Collection5/020.txt     \n",
            "  inflating: Collection5/021.ann     \n",
            "  inflating: Collection5/021.txt     \n",
            "  inflating: Collection5/022.ann     \n",
            "  inflating: Collection5/022.txt     \n",
            "  inflating: Collection5/023.ann     \n",
            "  inflating: Collection5/023.txt     \n",
            "  inflating: Collection5/025.ann     \n",
            "  inflating: Collection5/025.txt     \n",
            "  inflating: Collection5/026.ann     \n",
            "  inflating: Collection5/026.txt     \n",
            "  inflating: Collection5/027.ann     \n",
            "  inflating: Collection5/027.txt     \n",
            "  inflating: Collection5/028.ann     \n",
            "  inflating: Collection5/028.txt     \n",
            "  inflating: Collection5/029.ann     \n",
            "  inflating: Collection5/029.txt     \n",
            "  inflating: Collection5/030.ann     \n",
            "  inflating: Collection5/030.txt     \n",
            "  inflating: Collection5/031.ann     \n",
            "  inflating: Collection5/031.txt     \n",
            "  inflating: Collection5/032.ann     \n",
            "  inflating: Collection5/032.txt     \n",
            "  inflating: Collection5/033.ann     \n",
            "  inflating: Collection5/033.txt     \n",
            "  inflating: Collection5/034.ann     \n",
            "  inflating: Collection5/034.txt     \n",
            "  inflating: Collection5/035.ann     \n",
            "  inflating: Collection5/035.txt     \n",
            "  inflating: Collection5/036.ann     \n",
            "  inflating: Collection5/036.txt     \n",
            "  inflating: Collection5/037.ann     \n",
            "  inflating: Collection5/037.txt     \n",
            "  inflating: Collection5/038.ann     \n",
            "  inflating: Collection5/038.txt     \n",
            "  inflating: Collection5/039.ann     \n",
            "  inflating: Collection5/039.txt     \n",
            "  inflating: Collection5/03_12_12a.ann  \n",
            "  inflating: Collection5/03_12_12a.txt  \n",
            "  inflating: Collection5/03_12_12b.ann  \n",
            "  inflating: Collection5/03_12_12b.txt  \n",
            "  inflating: Collection5/03_12_12c.ann  \n",
            "  inflating: Collection5/03_12_12c.txt  \n",
            "  inflating: Collection5/03_12_12d.ann  \n",
            "  inflating: Collection5/03_12_12d.txt  \n",
            "  inflating: Collection5/03_12_12g.ann  \n",
            "  inflating: Collection5/03_12_12g.txt  \n",
            "  inflating: Collection5/03_12_12h.ann  \n",
            "  inflating: Collection5/03_12_12h.txt  \n",
            "  inflating: Collection5/040.ann     \n",
            "  inflating: Collection5/040.txt     \n",
            "  inflating: Collection5/041.ann     \n",
            "  inflating: Collection5/041.txt     \n",
            "  inflating: Collection5/042.ann     \n",
            "  inflating: Collection5/042.txt     \n",
            "  inflating: Collection5/043.ann     \n",
            "  inflating: Collection5/043.txt     \n",
            "  inflating: Collection5/044.ann     \n",
            "  inflating: Collection5/044.txt     \n",
            "  inflating: Collection5/045.ann     \n",
            "  inflating: Collection5/045.txt     \n",
            "  inflating: Collection5/046.ann     \n",
            "  inflating: Collection5/046.txt     \n",
            "  inflating: Collection5/047.ann     \n",
            "  inflating: Collection5/047.txt     \n",
            "  inflating: Collection5/048.ann     \n",
            "  inflating: Collection5/048.txt     \n",
            "  inflating: Collection5/049.ann     \n",
            "  inflating: Collection5/049.txt     \n",
            "  inflating: Collection5/04_02_13a_abdulatipov.ann  \n",
            "  inflating: Collection5/04_02_13a_abdulatipov.txt  \n",
            "  inflating: Collection5/04_03_13a_sorokin.ann  \n",
            "  inflating: Collection5/04_03_13a_sorokin.txt  \n",
            "  inflating: Collection5/04_12_12b.ann  \n",
            "  inflating: Collection5/04_12_12b.txt  \n",
            "  inflating: Collection5/04_12_12d.ann  \n",
            "  inflating: Collection5/04_12_12d.txt  \n",
            "  inflating: Collection5/04_12_12f.ann  \n",
            "  inflating: Collection5/04_12_12f.txt  \n",
            "  inflating: Collection5/04_12_12g.ann  \n",
            "  inflating: Collection5/04_12_12g.txt  \n",
            "  inflating: Collection5/04_12_12h_corr.ann  \n",
            "  inflating: Collection5/04_12_12h_corr.txt  \n",
            "  inflating: Collection5/050.ann     \n",
            "  inflating: Collection5/050.txt     \n",
            "  inflating: Collection5/051.ann     \n",
            "  inflating: Collection5/051.txt     \n",
            "  inflating: Collection5/052.ann     \n",
            "  inflating: Collection5/052.txt     \n",
            "  inflating: Collection5/053.ann     \n",
            "  inflating: Collection5/053.txt     \n",
            "  inflating: Collection5/054.ann     \n",
            "  inflating: Collection5/054.txt     \n",
            "  inflating: Collection5/055.ann     \n",
            "  inflating: Collection5/055.txt     \n",
            "  inflating: Collection5/056.ann     \n",
            "  inflating: Collection5/056.txt     \n",
            "  inflating: Collection5/057.ann     \n",
            "  inflating: Collection5/057.txt     \n",
            "  inflating: Collection5/058.ann     \n",
            "  inflating: Collection5/058.txt     \n",
            "  inflating: Collection5/059.ann     \n",
            "  inflating: Collection5/059.txt     \n",
            "  inflating: Collection5/060.ann     \n",
            "  inflating: Collection5/060.txt     \n",
            "  inflating: Collection5/061.ann     \n",
            "  inflating: Collection5/061.txt     \n",
            "  inflating: Collection5/062.ann     \n",
            "  inflating: Collection5/062.txt     \n",
            "  inflating: Collection5/063.ann     \n",
            "  inflating: Collection5/063.txt     \n",
            "  inflating: Collection5/064.ann     \n",
            "  inflating: Collection5/064.txt     \n",
            "  inflating: Collection5/065.ann     \n",
            "  inflating: Collection5/065.txt     \n",
            "  inflating: Collection5/066.ann     \n",
            "  inflating: Collection5/066.txt     \n",
            "  inflating: Collection5/067.ann     \n",
            "  inflating: Collection5/067.txt     \n",
            "  inflating: Collection5/068.ann     \n",
            "  inflating: Collection5/068.txt     \n",
            "  inflating: Collection5/069.ann     \n",
            "  inflating: Collection5/069.txt     \n",
            "  inflating: Collection5/070.ann     \n",
            "  inflating: Collection5/070.txt     \n",
            "  inflating: Collection5/071.ann     \n",
            "  inflating: Collection5/071.txt     \n",
            "  inflating: Collection5/072.ann     \n",
            "  inflating: Collection5/072.txt     \n",
            "  inflating: Collection5/073.ann     \n",
            "  inflating: Collection5/073.txt     \n",
            "  inflating: Collection5/074.ann     \n",
            "  inflating: Collection5/074.txt     \n",
            "  inflating: Collection5/075.ann     \n",
            "  inflating: Collection5/075.txt     \n",
            "  inflating: Collection5/076.ann     \n",
            "  inflating: Collection5/076.txt     \n",
            "  inflating: Collection5/077.ann     \n",
            "  inflating: Collection5/077.txt     \n",
            "  inflating: Collection5/078.ann     \n",
            "  inflating: Collection5/078.txt     \n",
            "  inflating: Collection5/079.ann     \n",
            "  inflating: Collection5/079.txt     \n",
            "  inflating: Collection5/080.ann     \n",
            "  inflating: Collection5/080.txt     \n",
            "  inflating: Collection5/081.ann     \n",
            "  inflating: Collection5/081.txt     \n",
            "  inflating: Collection5/082.ann     \n",
            "  inflating: Collection5/082.txt     \n",
            "  inflating: Collection5/083.ann     \n",
            "  inflating: Collection5/083.txt     \n",
            "  inflating: Collection5/084.ann     \n",
            "  inflating: Collection5/084.txt     \n",
            "  inflating: Collection5/085.ann     \n",
            "  inflating: Collection5/085.txt     \n",
            "  inflating: Collection5/086.ann     \n",
            "  inflating: Collection5/086.txt     \n",
            "  inflating: Collection5/087.ann     \n",
            "  inflating: Collection5/087.txt     \n",
            "  inflating: Collection5/088.ann     \n",
            "  inflating: Collection5/088.txt     \n",
            "  inflating: Collection5/089.ann     \n",
            "  inflating: Collection5/089.txt     \n",
            "  inflating: Collection5/090.ann     \n",
            "  inflating: Collection5/090.txt     \n",
            "  inflating: Collection5/091.ann     \n",
            "  inflating: Collection5/091.txt     \n",
            "  inflating: Collection5/092.ann     \n",
            "  inflating: Collection5/092.txt     \n",
            "  inflating: Collection5/093.ann     \n",
            "  inflating: Collection5/093.txt     \n",
            "  inflating: Collection5/094.ann     \n",
            "  inflating: Collection5/094.txt     \n",
            "  inflating: Collection5/095.ann     \n",
            "  inflating: Collection5/095.txt     \n",
            "  inflating: Collection5/096.ann     \n",
            "  inflating: Collection5/096.txt     \n",
            "  inflating: Collection5/097.ann     \n",
            "  inflating: Collection5/097.txt     \n",
            "  inflating: Collection5/098.ann     \n",
            "  inflating: Collection5/098.txt     \n",
            "  inflating: Collection5/099.ann     \n",
            "  inflating: Collection5/099.txt     \n",
            "  inflating: Collection5/09_01_13.ann  \n",
            "  inflating: Collection5/09_01_13.txt  \n",
            "  inflating: Collection5/09_01_13a.ann  \n",
            "  inflating: Collection5/09_01_13a.txt  \n",
            "  inflating: Collection5/09_01_13c.ann  \n",
            "  inflating: Collection5/09_01_13c.txt  \n",
            "  inflating: Collection5/09_01_13d.ann  \n",
            "  inflating: Collection5/09_01_13d.txt  \n",
            "  inflating: Collection5/09_01_13e.ann  \n",
            "  inflating: Collection5/09_01_13e.txt  \n",
            "  inflating: Collection5/09_01_13h.ann  \n",
            "  inflating: Collection5/09_01_13h.txt  \n",
            "  inflating: Collection5/09_01_13i.ann  \n",
            "  inflating: Collection5/09_01_13i.txt  \n",
            "  inflating: Collection5/100.ann     \n",
            "  inflating: Collection5/100.txt     \n",
            "  inflating: Collection5/1000.ann    \n",
            "  inflating: Collection5/1000.txt    \n",
            "  inflating: Collection5/1001.ann    \n",
            "  inflating: Collection5/1001.txt    \n",
            "  inflating: Collection5/1002.ann    \n",
            "  inflating: Collection5/1002.txt    \n",
            "  inflating: Collection5/1003.ann    \n",
            "  inflating: Collection5/1003.txt    \n",
            "  inflating: Collection5/1004.ann    \n",
            "  inflating: Collection5/1004.txt    \n",
            "  inflating: Collection5/1005.ann    \n",
            "  inflating: Collection5/1005.txt    \n",
            "  inflating: Collection5/1006.ann    \n",
            "  inflating: Collection5/1006.txt    \n",
            "  inflating: Collection5/1007.ann    \n",
            "  inflating: Collection5/1007.txt    \n",
            "  inflating: Collection5/1008.ann    \n",
            "  inflating: Collection5/1008.txt    \n",
            "  inflating: Collection5/1009.ann    \n",
            "  inflating: Collection5/1009.txt    \n",
            "  inflating: Collection5/101.ann     \n",
            "  inflating: Collection5/101.txt     \n",
            "  inflating: Collection5/1010.ann    \n",
            "  inflating: Collection5/1010.txt    \n",
            "  inflating: Collection5/1011.ann    \n",
            "  inflating: Collection5/1011.txt    \n",
            "  inflating: Collection5/1012.ann    \n",
            "  inflating: Collection5/1012.txt    \n",
            "  inflating: Collection5/1013.ann    \n",
            "  inflating: Collection5/1013.txt    \n",
            "  inflating: Collection5/1014.ann    \n",
            "  inflating: Collection5/1014.txt    \n",
            "  inflating: Collection5/1015.ann    \n",
            "  inflating: Collection5/1015.txt    \n",
            "  inflating: Collection5/1016.ann    \n",
            "  inflating: Collection5/1016.txt    \n",
            "  inflating: Collection5/1017.ann    \n",
            "  inflating: Collection5/1017.txt    \n",
            "  inflating: Collection5/1018.ann    \n",
            "  inflating: Collection5/1018.txt    \n",
            "  inflating: Collection5/1019.ann    \n",
            "  inflating: Collection5/1019.txt    \n",
            "  inflating: Collection5/102.ann     \n",
            "  inflating: Collection5/102.txt     \n",
            "  inflating: Collection5/1020.ann    \n",
            "  inflating: Collection5/1020.txt    \n",
            "  inflating: Collection5/1021.ann    \n",
            "  inflating: Collection5/1021.txt    \n",
            "  inflating: Collection5/1022.ann    \n",
            "  inflating: Collection5/1022.txt    \n",
            "  inflating: Collection5/1023.ann    \n",
            "  inflating: Collection5/1023.txt    \n",
            "  inflating: Collection5/1024.ann    \n",
            "  inflating: Collection5/1024.txt    \n",
            "  inflating: Collection5/1025.ann    \n",
            "  inflating: Collection5/1025.txt    \n",
            "  inflating: Collection5/1026.ann    \n",
            "  inflating: Collection5/1026.txt    \n",
            "  inflating: Collection5/1027.ann    \n",
            "  inflating: Collection5/1027.txt    \n",
            "  inflating: Collection5/1028.ann    \n",
            "  inflating: Collection5/1028.txt    \n",
            "  inflating: Collection5/1029.ann    \n",
            "  inflating: Collection5/1029.txt    \n",
            "  inflating: Collection5/103.ann     \n",
            "  inflating: Collection5/103.txt     \n",
            "  inflating: Collection5/1030.ann    \n",
            "  inflating: Collection5/1030.txt    \n",
            "  inflating: Collection5/1031.ann    \n",
            "  inflating: Collection5/1031.txt    \n",
            "  inflating: Collection5/1032.ann    \n",
            "  inflating: Collection5/1032.txt    \n",
            "  inflating: Collection5/1033.ann    \n",
            "  inflating: Collection5/1033.txt    \n",
            "  inflating: Collection5/1034.ann    \n",
            "  inflating: Collection5/1034.txt    \n",
            "  inflating: Collection5/1035.ann    \n",
            "  inflating: Collection5/1035.txt    \n",
            "  inflating: Collection5/1036.ann    \n",
            "  inflating: Collection5/1036.txt    \n",
            "  inflating: Collection5/1037.ann    \n",
            "  inflating: Collection5/1037.txt    \n",
            "  inflating: Collection5/1038.ann    \n",
            "  inflating: Collection5/1038.txt    \n",
            "  inflating: Collection5/1039.ann    \n",
            "  inflating: Collection5/1039.txt    \n",
            "  inflating: Collection5/104.ann     \n",
            "  inflating: Collection5/104.txt     \n",
            "  inflating: Collection5/1040.ann    \n",
            "  inflating: Collection5/1040.txt    \n",
            "  inflating: Collection5/1041.ann    \n",
            "  inflating: Collection5/1041.txt    \n",
            "  inflating: Collection5/1042.ann    \n",
            "  inflating: Collection5/1042.txt    \n",
            "  inflating: Collection5/1043.ann    \n",
            "  inflating: Collection5/1043.txt    \n",
            "  inflating: Collection5/1044.ann    \n",
            "  inflating: Collection5/1044.txt    \n",
            "  inflating: Collection5/1045.ann    \n",
            "  inflating: Collection5/1045.txt    \n",
            "  inflating: Collection5/1046.ann    \n",
            "  inflating: Collection5/1046.txt    \n",
            "  inflating: Collection5/1047.ann    \n",
            "  inflating: Collection5/1047.txt    \n",
            "  inflating: Collection5/1048.ann    \n",
            "  inflating: Collection5/1048.txt    \n",
            "  inflating: Collection5/1049.ann    \n",
            "  inflating: Collection5/1049.txt    \n",
            "  inflating: Collection5/105.ann     \n",
            "  inflating: Collection5/105.txt     \n",
            "  inflating: Collection5/1050.ann    \n",
            "  inflating: Collection5/1050.txt    \n",
            "  inflating: Collection5/106.ann     \n",
            "  inflating: Collection5/106.txt     \n",
            "  inflating: Collection5/107.ann     \n",
            "  inflating: Collection5/107.txt     \n",
            "  inflating: Collection5/108.ann     \n",
            "  inflating: Collection5/108.txt     \n",
            "  inflating: Collection5/109.ann     \n",
            "  inflating: Collection5/109.txt     \n",
            "  inflating: Collection5/10_01_13a.ann  \n",
            "  inflating: Collection5/10_01_13a.txt  \n",
            "  inflating: Collection5/10_01_13d.ann  \n",
            "  inflating: Collection5/10_01_13d.txt  \n",
            "  inflating: Collection5/10_01_13i.ann  \n",
            "  inflating: Collection5/10_01_13i.txt  \n",
            "  inflating: Collection5/110.ann     \n",
            "  inflating: Collection5/110.txt     \n",
            "  inflating: Collection5/1100.ann    \n",
            "  inflating: Collection5/1100.txt    \n",
            "  inflating: Collection5/1101.ann    \n",
            "  inflating: Collection5/1101.txt    \n",
            "  inflating: Collection5/1102.ann    \n",
            "  inflating: Collection5/1102.txt    \n",
            "  inflating: Collection5/1103.ann    \n",
            "  inflating: Collection5/1103.txt    \n",
            "  inflating: Collection5/1104.ann    \n",
            "  inflating: Collection5/1104.txt    \n",
            "  inflating: Collection5/1105.ann    \n",
            "  inflating: Collection5/1105.txt    \n",
            "  inflating: Collection5/1106.ann    \n",
            "  inflating: Collection5/1106.txt    \n",
            "  inflating: Collection5/1107.ann    \n",
            "  inflating: Collection5/1107.txt    \n",
            "  inflating: Collection5/1108.ann    \n",
            "  inflating: Collection5/1108.txt    \n",
            "  inflating: Collection5/1109.ann    \n",
            "  inflating: Collection5/1109.txt    \n",
            "  inflating: Collection5/111.ann     \n",
            "  inflating: Collection5/111.txt     \n",
            "  inflating: Collection5/1110.ann    \n",
            "  inflating: Collection5/1110.txt    \n",
            "  inflating: Collection5/1111.ann    \n",
            "  inflating: Collection5/1111.txt    \n",
            "  inflating: Collection5/1112.ann    \n",
            "  inflating: Collection5/1112.txt    \n",
            "  inflating: Collection5/1113.ann    \n",
            "  inflating: Collection5/1113.txt    \n",
            "  inflating: Collection5/1114.ann    \n",
            "  inflating: Collection5/1114.txt    \n",
            "  inflating: Collection5/1115.ann    \n",
            "  inflating: Collection5/1115.txt    \n",
            "  inflating: Collection5/1116.ann    \n",
            "  inflating: Collection5/1116.txt    \n",
            "  inflating: Collection5/1117.ann    \n",
            "  inflating: Collection5/1117.txt    \n",
            "  inflating: Collection5/1118.ann    \n",
            "  inflating: Collection5/1118.txt    \n",
            "  inflating: Collection5/1119.ann    \n",
            "  inflating: Collection5/1119.txt    \n",
            "  inflating: Collection5/112.ann     \n",
            "  inflating: Collection5/112.txt     \n",
            "  inflating: Collection5/1120.ann    \n",
            "  inflating: Collection5/1120.txt    \n",
            "  inflating: Collection5/1121.ann    \n",
            "  inflating: Collection5/1121.txt    \n",
            "  inflating: Collection5/1122.ann    \n",
            "  inflating: Collection5/1122.txt    \n",
            "  inflating: Collection5/1123.ann    \n",
            "  inflating: Collection5/1123.txt    \n",
            "  inflating: Collection5/1124.ann    \n",
            "  inflating: Collection5/1124.txt    \n",
            "  inflating: Collection5/1125.ann    \n",
            "  inflating: Collection5/1125.txt    \n",
            "  inflating: Collection5/1126.ann    \n",
            "  inflating: Collection5/1126.txt    \n",
            "  inflating: Collection5/1127.ann    \n",
            "  inflating: Collection5/1127.txt    \n",
            "  inflating: Collection5/1128.ann    \n",
            "  inflating: Collection5/1128.txt    \n",
            "  inflating: Collection5/113.ann     \n",
            "  inflating: Collection5/113.txt     \n",
            "  inflating: Collection5/1130.ann    \n",
            "  inflating: Collection5/1130.txt    \n",
            "  inflating: Collection5/1131.ann    \n",
            "  inflating: Collection5/1131.txt    \n",
            "  inflating: Collection5/1132.ann    \n",
            "  inflating: Collection5/1132.txt    \n",
            "  inflating: Collection5/1133.ann    \n",
            "  inflating: Collection5/1133.txt    \n",
            "  inflating: Collection5/1134.ann    \n",
            "  inflating: Collection5/1134.txt    \n",
            "  inflating: Collection5/1135.ann    \n",
            "  inflating: Collection5/1135.txt    \n",
            "  inflating: Collection5/1136.ann    \n",
            "  inflating: Collection5/1136.txt    \n",
            "  inflating: Collection5/1137.ann    \n",
            "  inflating: Collection5/1137.txt    \n",
            "  inflating: Collection5/1138.ann    \n",
            "  inflating: Collection5/1138.txt    \n",
            "  inflating: Collection5/1139.ann    \n",
            "  inflating: Collection5/1139.txt    \n",
            "  inflating: Collection5/114.ann     \n",
            "  inflating: Collection5/114.txt     \n",
            "  inflating: Collection5/1140.ann    \n",
            "  inflating: Collection5/1140.txt    \n",
            "  inflating: Collection5/1141.ann    \n",
            "  inflating: Collection5/1141.txt    \n",
            "  inflating: Collection5/1142.ann    \n",
            "  inflating: Collection5/1142.txt    \n",
            "  inflating: Collection5/1143.ann    \n",
            "  inflating: Collection5/1143.txt    \n",
            "  inflating: Collection5/1144.ann    \n",
            "  inflating: Collection5/1144.txt    \n",
            "  inflating: Collection5/1145.ann    \n",
            "  inflating: Collection5/1145.txt    \n",
            "  inflating: Collection5/1146.ann    \n",
            "  inflating: Collection5/1146.txt    \n",
            "  inflating: Collection5/1147.ann    \n",
            "  inflating: Collection5/1147.txt    \n",
            "  inflating: Collection5/1148.ann    \n",
            "  inflating: Collection5/1148.txt    \n",
            "  inflating: Collection5/1149.ann    \n",
            "  inflating: Collection5/1149.txt    \n",
            "  inflating: Collection5/115.ann     \n",
            "  inflating: Collection5/115.txt     \n",
            "  inflating: Collection5/1150.ann    \n",
            "  inflating: Collection5/1150.txt    \n",
            "  inflating: Collection5/1151.ann    \n",
            "  inflating: Collection5/1151.txt    \n",
            "  inflating: Collection5/1152.ann    \n",
            "  inflating: Collection5/1152.txt    \n",
            "  inflating: Collection5/1153.ann    \n",
            "  inflating: Collection5/1153.txt    \n",
            "  inflating: Collection5/1154.ann    \n",
            "  inflating: Collection5/1154.txt    \n",
            "  inflating: Collection5/1155.ann    \n",
            "  inflating: Collection5/1155.txt    \n",
            "  inflating: Collection5/1156.ann    \n",
            "  inflating: Collection5/1156.txt    \n",
            "  inflating: Collection5/1157.ann    \n",
            "  inflating: Collection5/1157.txt    \n",
            "  inflating: Collection5/1158.ann    \n",
            "  inflating: Collection5/1158.txt    \n",
            "  inflating: Collection5/1159.ann    \n",
            "  inflating: Collection5/1159.txt    \n",
            "  inflating: Collection5/116.ann     \n",
            "  inflating: Collection5/116.txt     \n",
            "  inflating: Collection5/1160.ann    \n",
            "  inflating: Collection5/1160.txt    \n",
            "  inflating: Collection5/1161.ann    \n",
            "  inflating: Collection5/1161.txt    \n",
            "  inflating: Collection5/1162.ann    \n",
            "  inflating: Collection5/1162.txt    \n",
            "  inflating: Collection5/1163.ann    \n",
            "  inflating: Collection5/1163.txt    \n",
            "  inflating: Collection5/1164.ann    \n",
            "  inflating: Collection5/1164.txt    \n",
            "  inflating: Collection5/1165.ann    \n",
            "  inflating: Collection5/1165.txt    \n",
            "  inflating: Collection5/1166.ann    \n",
            "  inflating: Collection5/1166.txt    \n",
            "  inflating: Collection5/1167.ann    \n",
            "  inflating: Collection5/1167.txt    \n",
            "  inflating: Collection5/1168.ann    \n",
            "  inflating: Collection5/1168.txt    \n",
            "  inflating: Collection5/1169.ann    \n",
            "  inflating: Collection5/1169.txt    \n",
            "  inflating: Collection5/117.ann     \n",
            "  inflating: Collection5/117.txt     \n",
            "  inflating: Collection5/1170.ann    \n",
            "  inflating: Collection5/1170.txt    \n",
            "  inflating: Collection5/1171.ann    \n",
            "  inflating: Collection5/1171.txt    \n",
            "  inflating: Collection5/1172.ann    \n",
            "  inflating: Collection5/1172.txt    \n",
            "  inflating: Collection5/1173.ann    \n",
            "  inflating: Collection5/1173.txt    \n",
            "  inflating: Collection5/1174.ann    \n",
            "  inflating: Collection5/1174.txt    \n",
            "  inflating: Collection5/1175.ann    \n",
            "  inflating: Collection5/1175.txt    \n",
            "  inflating: Collection5/1176.ann    \n",
            "  inflating: Collection5/1176.txt    \n",
            "  inflating: Collection5/1177.ann    \n",
            "  inflating: Collection5/1177.txt    \n",
            "  inflating: Collection5/1178.ann    \n",
            "  inflating: Collection5/1178.txt    \n",
            "  inflating: Collection5/1179.ann    \n",
            "  inflating: Collection5/1179.txt    \n",
            "  inflating: Collection5/118.ann     \n",
            "  inflating: Collection5/118.txt     \n",
            "  inflating: Collection5/1180.ann    \n",
            "  inflating: Collection5/1180.txt    \n",
            "  inflating: Collection5/1181.ann    \n",
            "  inflating: Collection5/1181.txt    \n",
            "  inflating: Collection5/1182.ann    \n",
            "  inflating: Collection5/1182.txt    \n",
            "  inflating: Collection5/1183.ann    \n",
            "  inflating: Collection5/1183.txt    \n",
            "  inflating: Collection5/1184.ann    \n",
            "  inflating: Collection5/1184.txt    \n",
            "  inflating: Collection5/1185.ann    \n",
            "  inflating: Collection5/1185.txt    \n",
            "  inflating: Collection5/1186.ann    \n",
            "  inflating: Collection5/1186.txt    \n",
            "  inflating: Collection5/1187.ann    \n",
            "  inflating: Collection5/1187.txt    \n",
            "  inflating: Collection5/1188.ann    \n",
            "  inflating: Collection5/1188.txt    \n",
            "  inflating: Collection5/1189.ann    \n",
            "  inflating: Collection5/1189.txt    \n",
            "  inflating: Collection5/119.ann     \n",
            "  inflating: Collection5/119.txt     \n",
            "  inflating: Collection5/1190.ann    \n",
            "  inflating: Collection5/1190.txt    \n",
            "  inflating: Collection5/1191.ann    \n",
            "  inflating: Collection5/1191.txt    \n",
            "  inflating: Collection5/1192.ann    \n",
            "  inflating: Collection5/1192.txt    \n",
            "  inflating: Collection5/1193.ann    \n",
            "  inflating: Collection5/1193.txt    \n",
            "  inflating: Collection5/1194.ann    \n",
            "  inflating: Collection5/1194.txt    \n",
            "  inflating: Collection5/1195.ann    \n",
            "  inflating: Collection5/1195.txt    \n",
            "  inflating: Collection5/1196.ann    \n",
            "  inflating: Collection5/1196.txt    \n",
            "  inflating: Collection5/1197.ann    \n",
            "  inflating: Collection5/1197.txt    \n",
            "  inflating: Collection5/1198.ann    \n",
            "  inflating: Collection5/1198.txt    \n",
            "  inflating: Collection5/1199.ann    \n",
            "  inflating: Collection5/1199.txt    \n",
            "  inflating: Collection5/11_01_13b.ann  \n",
            "  inflating: Collection5/11_01_13b.txt  \n",
            "  inflating: Collection5/11_01_13e.ann  \n",
            "  inflating: Collection5/11_01_13e.txt  \n",
            "  inflating: Collection5/120.ann     \n",
            "  inflating: Collection5/120.txt     \n",
            "  inflating: Collection5/1200.ann    \n",
            "  inflating: Collection5/1200.txt    \n",
            "  inflating: Collection5/121.ann     \n",
            "  inflating: Collection5/121.txt     \n",
            "  inflating: Collection5/122.ann     \n",
            "  inflating: Collection5/122.txt     \n",
            "  inflating: Collection5/123.ann     \n",
            "  inflating: Collection5/123.txt     \n",
            "  inflating: Collection5/124.ann     \n",
            "  inflating: Collection5/124.txt     \n",
            "  inflating: Collection5/125.ann     \n",
            "  inflating: Collection5/125.txt     \n",
            "  inflating: Collection5/126.ann     \n",
            "  inflating: Collection5/126.txt     \n",
            "  inflating: Collection5/127.ann     \n",
            "  inflating: Collection5/127.txt     \n",
            "  inflating: Collection5/128.ann     \n",
            "  inflating: Collection5/128.txt     \n",
            "  inflating: Collection5/129.ann     \n",
            "  inflating: Collection5/129.txt     \n",
            "  inflating: Collection5/130.ann     \n",
            "  inflating: Collection5/130.txt     \n",
            "  inflating: Collection5/131.ann     \n",
            "  inflating: Collection5/131.txt     \n",
            "  inflating: Collection5/132.ann     \n",
            "  inflating: Collection5/132.txt     \n",
            "  inflating: Collection5/133.ann     \n",
            "  inflating: Collection5/133.txt     \n",
            "  inflating: Collection5/134.ann     \n",
            "  inflating: Collection5/134.txt     \n",
            "  inflating: Collection5/135.ann     \n",
            "  inflating: Collection5/135.txt     \n",
            "  inflating: Collection5/136.ann     \n",
            "  inflating: Collection5/136.txt     \n",
            "  inflating: Collection5/137.ann     \n",
            "  inflating: Collection5/137.txt     \n",
            "  inflating: Collection5/138.ann     \n",
            "  inflating: Collection5/138.txt     \n",
            "  inflating: Collection5/139.ann     \n",
            "  inflating: Collection5/139.txt     \n",
            "  inflating: Collection5/140.ann     \n",
            "  inflating: Collection5/140.txt     \n",
            "  inflating: Collection5/141.ann     \n",
            "  inflating: Collection5/141.txt     \n",
            "  inflating: Collection5/142.ann     \n",
            "  inflating: Collection5/142.txt     \n",
            "  inflating: Collection5/143.ann     \n",
            "  inflating: Collection5/143.txt     \n",
            "  inflating: Collection5/144.ann     \n",
            "  inflating: Collection5/144.txt     \n",
            "  inflating: Collection5/145.ann     \n",
            "  inflating: Collection5/145.txt     \n",
            "  inflating: Collection5/146.ann     \n",
            "  inflating: Collection5/146.txt     \n",
            "  inflating: Collection5/147.ann     \n",
            "  inflating: Collection5/147.txt     \n",
            "  inflating: Collection5/148.ann     \n",
            "  inflating: Collection5/148.txt     \n",
            "  inflating: Collection5/149.ann     \n",
            "  inflating: Collection5/149.txt     \n",
            "  inflating: Collection5/14_01_13c.ann  \n",
            "  inflating: Collection5/14_01_13c.txt  \n",
            "  inflating: Collection5/14_01_13g.ann  \n",
            "  inflating: Collection5/14_01_13g.txt  \n",
            "  inflating: Collection5/14_01_13i.ann  \n",
            "  inflating: Collection5/14_01_13i.txt  \n",
            "  inflating: Collection5/150.ann     \n",
            "  inflating: Collection5/150.txt     \n",
            "  inflating: Collection5/151.ann     \n",
            "  inflating: Collection5/151.txt     \n",
            "  inflating: Collection5/152.ann     \n",
            "  inflating: Collection5/152.txt     \n",
            "  inflating: Collection5/153.ann     \n",
            "  inflating: Collection5/153.txt     \n",
            "  inflating: Collection5/154.ann     \n",
            "  inflating: Collection5/154.txt     \n",
            "  inflating: Collection5/155.ann     \n",
            "  inflating: Collection5/155.txt     \n",
            "  inflating: Collection5/156.ann     \n",
            "  inflating: Collection5/156.txt     \n",
            "  inflating: Collection5/157.ann     \n",
            "  inflating: Collection5/157.txt     \n",
            "  inflating: Collection5/158.ann     \n",
            "  inflating: Collection5/158.txt     \n",
            "  inflating: Collection5/159.ann     \n",
            "  inflating: Collection5/159.txt     \n",
            "  inflating: Collection5/15_01_13a.ann  \n",
            "  inflating: Collection5/15_01_13a.txt  \n",
            "  inflating: Collection5/15_01_13b.ann  \n",
            "  inflating: Collection5/15_01_13b.txt  \n",
            "  inflating: Collection5/15_01_13e.ann  \n",
            "  inflating: Collection5/15_01_13e.txt  \n",
            "  inflating: Collection5/15_01_13f.ann  \n",
            "  inflating: Collection5/15_01_13f.txt  \n",
            "  inflating: Collection5/160.ann     \n",
            "  inflating: Collection5/160.txt     \n",
            "  inflating: Collection5/161.ann     \n",
            "  inflating: Collection5/161.txt     \n",
            "  inflating: Collection5/162.ann     \n",
            "  inflating: Collection5/162.txt     \n",
            "  inflating: Collection5/163.ann     \n",
            "  inflating: Collection5/163.txt     \n",
            "  inflating: Collection5/164.ann     \n",
            "  inflating: Collection5/164.txt     \n",
            "  inflating: Collection5/165.ann     \n",
            "  inflating: Collection5/165.txt     \n",
            "  inflating: Collection5/166.ann     \n",
            "  inflating: Collection5/166.txt     \n",
            "  inflating: Collection5/167.ann     \n",
            "  inflating: Collection5/167.txt     \n",
            "  inflating: Collection5/168.ann     \n",
            "  inflating: Collection5/168.txt     \n",
            "  inflating: Collection5/169.ann     \n",
            "  inflating: Collection5/169.txt     \n",
            "  inflating: Collection5/170.ann     \n",
            "  inflating: Collection5/170.txt     \n",
            "  inflating: Collection5/171.ann     \n",
            "  inflating: Collection5/171.txt     \n",
            "  inflating: Collection5/172.ann     \n",
            "  inflating: Collection5/172.txt     \n",
            "  inflating: Collection5/173.ann     \n",
            "  inflating: Collection5/173.txt     \n",
            "  inflating: Collection5/174.ann     \n",
            "  inflating: Collection5/174.txt     \n",
            "  inflating: Collection5/175.ann     \n",
            "  inflating: Collection5/175.txt     \n",
            "  inflating: Collection5/176.ann     \n",
            "  inflating: Collection5/176.txt     \n",
            "  inflating: Collection5/177.ann     \n",
            "  inflating: Collection5/177.txt     \n",
            "  inflating: Collection5/178.ann     \n",
            "  inflating: Collection5/178.txt     \n",
            "  inflating: Collection5/179.ann     \n",
            "  inflating: Collection5/179.txt     \n",
            "  inflating: Collection5/180.ann     \n",
            "  inflating: Collection5/180.txt     \n",
            "  inflating: Collection5/181.ann     \n",
            "  inflating: Collection5/181.txt     \n",
            "  inflating: Collection5/182.ann     \n",
            "  inflating: Collection5/182.txt     \n",
            "  inflating: Collection5/183.ann     \n",
            "  inflating: Collection5/183.txt     \n",
            "  inflating: Collection5/184.ann     \n",
            "  inflating: Collection5/184.txt     \n",
            "  inflating: Collection5/185.ann     \n",
            "  inflating: Collection5/185.txt     \n",
            "  inflating: Collection5/186.ann     \n",
            "  inflating: Collection5/186.txt     \n",
            "  inflating: Collection5/187.ann     \n",
            "  inflating: Collection5/187.txt     \n",
            "  inflating: Collection5/188.ann     \n",
            "  inflating: Collection5/188.txt     \n",
            "  inflating: Collection5/189.ann     \n",
            "  inflating: Collection5/189.txt     \n",
            "  inflating: Collection5/190.ann     \n",
            "  inflating: Collection5/190.txt     \n",
            "  inflating: Collection5/191.ann     \n",
            "  inflating: Collection5/191.txt     \n",
            "  inflating: Collection5/192.ann     \n",
            "  inflating: Collection5/192.txt     \n",
            "  inflating: Collection5/193.ann     \n",
            "  inflating: Collection5/193.txt     \n",
            "  inflating: Collection5/194.ann     \n",
            "  inflating: Collection5/194.txt     \n",
            "  inflating: Collection5/195.ann     \n",
            "  inflating: Collection5/195.txt     \n",
            "  inflating: Collection5/196.ann     \n",
            "  inflating: Collection5/196.txt     \n",
            "  inflating: Collection5/197.ann     \n",
            "  inflating: Collection5/197.txt     \n",
            "  inflating: Collection5/198.ann     \n",
            "  inflating: Collection5/198.txt     \n",
            "  inflating: Collection5/199.ann     \n",
            "  inflating: Collection5/199.txt     \n",
            "  inflating: Collection5/19_11_12d.ann  \n",
            "  inflating: Collection5/19_11_12d.txt  \n",
            "  inflating: Collection5/19_11_12h.ann  \n",
            "  inflating: Collection5/19_11_12h.txt  \n",
            "  inflating: Collection5/200.ann     \n",
            "  inflating: Collection5/200.txt     \n",
            "  inflating: Collection5/2001.ann    \n",
            "  inflating: Collection5/2001.txt    \n",
            "  inflating: Collection5/2002.ann    \n",
            "  inflating: Collection5/2002.txt    \n",
            "  inflating: Collection5/2003.ann    \n",
            "  inflating: Collection5/2003.txt    \n",
            "  inflating: Collection5/2004.ann    \n",
            "  inflating: Collection5/2004.txt    \n",
            "  inflating: Collection5/2005.ann    \n",
            "  inflating: Collection5/2005.txt    \n",
            "  inflating: Collection5/2006.ann    \n",
            "  inflating: Collection5/2006.txt    \n",
            "  inflating: Collection5/2007.ann    \n",
            "  inflating: Collection5/2007.txt    \n",
            "  inflating: Collection5/2008.ann    \n",
            "  inflating: Collection5/2008.txt    \n",
            "  inflating: Collection5/2009.ann    \n",
            "  inflating: Collection5/2009.txt    \n",
            "  inflating: Collection5/201.ann     \n",
            "  inflating: Collection5/201.txt     \n",
            "  inflating: Collection5/2010.ann    \n",
            "  inflating: Collection5/2010.txt    \n",
            "  inflating: Collection5/2011.ann    \n",
            "  inflating: Collection5/2011.txt    \n",
            "  inflating: Collection5/2012.ann    \n",
            "  inflating: Collection5/2012.txt    \n",
            "  inflating: Collection5/2013.ann    \n",
            "  inflating: Collection5/2013.txt    \n",
            "  inflating: Collection5/2014.ann    \n",
            "  inflating: Collection5/2014.txt    \n",
            "  inflating: Collection5/2015.ann    \n",
            "  inflating: Collection5/2015.txt    \n",
            "  inflating: Collection5/2016.ann    \n",
            "  inflating: Collection5/2016.txt    \n",
            "  inflating: Collection5/2017.ann    \n",
            "  inflating: Collection5/2017.txt    \n",
            "  inflating: Collection5/2018.ann    \n",
            "  inflating: Collection5/2018.txt    \n",
            "  inflating: Collection5/2019.ann    \n",
            "  inflating: Collection5/2019.txt    \n",
            "  inflating: Collection5/202.ann     \n",
            "  inflating: Collection5/202.txt     \n",
            "  inflating: Collection5/2020.ann    \n",
            "  inflating: Collection5/2020.txt    \n",
            "  inflating: Collection5/2021.ann    \n",
            "  inflating: Collection5/2021.txt    \n",
            "  inflating: Collection5/2022.ann    \n",
            "  inflating: Collection5/2022.txt    \n",
            "  inflating: Collection5/2023.ann    \n",
            "  inflating: Collection5/2023.txt    \n",
            "  inflating: Collection5/2024.ann    \n",
            "  inflating: Collection5/2024.txt    \n",
            "  inflating: Collection5/2025.ann    \n",
            "  inflating: Collection5/2025.txt    \n",
            "  inflating: Collection5/2026.ann    \n",
            "  inflating: Collection5/2026.txt    \n",
            "  inflating: Collection5/2027.ann    \n",
            "  inflating: Collection5/2027.txt    \n",
            "  inflating: Collection5/2028.ann    \n",
            "  inflating: Collection5/2028.txt    \n",
            "  inflating: Collection5/2029.ann    \n",
            "  inflating: Collection5/2029.txt    \n",
            "  inflating: Collection5/203.ann     \n",
            "  inflating: Collection5/203.txt     \n",
            "  inflating: Collection5/2030.ann    \n",
            "  inflating: Collection5/2030.txt    \n",
            "  inflating: Collection5/2031.ann    \n",
            "  inflating: Collection5/2031.txt    \n",
            "  inflating: Collection5/2032.ann    \n",
            "  inflating: Collection5/2032.txt    \n",
            "  inflating: Collection5/2034.ann    \n",
            "  inflating: Collection5/2034.txt    \n",
            "  inflating: Collection5/2035.ann    \n",
            "  inflating: Collection5/2035.txt    \n",
            "  inflating: Collection5/2036.ann    \n",
            "  inflating: Collection5/2036.txt    \n",
            "  inflating: Collection5/2037.ann    \n",
            "  inflating: Collection5/2037.txt    \n",
            "  inflating: Collection5/2038.ann    \n",
            "  inflating: Collection5/2038.txt    \n",
            "  inflating: Collection5/2039.ann    \n",
            "  inflating: Collection5/2039.txt    \n",
            "  inflating: Collection5/204.ann     \n",
            "  inflating: Collection5/204.txt     \n",
            "  inflating: Collection5/2040.ann    \n",
            "  inflating: Collection5/2040.txt    \n",
            "  inflating: Collection5/2041.ann    \n",
            "  inflating: Collection5/2041.txt    \n",
            "  inflating: Collection5/2042.ann    \n",
            "  inflating: Collection5/2042.txt    \n",
            "  inflating: Collection5/2043.ann    \n",
            "  inflating: Collection5/2043.txt    \n",
            "  inflating: Collection5/2044.ann    \n",
            "  inflating: Collection5/2044.txt    \n",
            "  inflating: Collection5/2045.ann    \n",
            "  inflating: Collection5/2045.txt    \n",
            "  inflating: Collection5/2046.ann    \n",
            "  inflating: Collection5/2046.txt    \n",
            "  inflating: Collection5/2047.ann    \n",
            "  inflating: Collection5/2047.txt    \n",
            "  inflating: Collection5/2048.ann    \n",
            "  inflating: Collection5/2048.txt    \n",
            "  inflating: Collection5/2049.ann    \n",
            "  inflating: Collection5/2049.txt    \n",
            "  inflating: Collection5/205.ann     \n",
            "  inflating: Collection5/205.txt     \n",
            "  inflating: Collection5/2050.ann    \n",
            "  inflating: Collection5/2050.txt    \n",
            "  inflating: Collection5/206.ann     \n",
            "  inflating: Collection5/206.txt     \n",
            "  inflating: Collection5/207.ann     \n",
            "  inflating: Collection5/207.txt     \n",
            "  inflating: Collection5/208.ann     \n",
            "  inflating: Collection5/208.txt     \n",
            "  inflating: Collection5/209.ann     \n",
            "  inflating: Collection5/209.txt     \n",
            "  inflating: Collection5/20_11_12a.ann  \n",
            "  inflating: Collection5/20_11_12a.txt  \n",
            "  inflating: Collection5/20_11_12b.ann  \n",
            "  inflating: Collection5/20_11_12b.txt  \n",
            "  inflating: Collection5/20_11_12c.ann  \n",
            "  inflating: Collection5/20_11_12c.txt  \n",
            "  inflating: Collection5/20_11_12d.ann  \n",
            "  inflating: Collection5/20_11_12d.txt  \n",
            "  inflating: Collection5/20_11_12i.ann  \n",
            "  inflating: Collection5/20_11_12i.txt  \n",
            "  inflating: Collection5/210.ann     \n",
            "  inflating: Collection5/210.txt     \n",
            "  inflating: Collection5/211.ann     \n",
            "  inflating: Collection5/211.txt     \n",
            "  inflating: Collection5/212.ann     \n",
            "  inflating: Collection5/212.txt     \n",
            "  inflating: Collection5/213.ann     \n",
            "  inflating: Collection5/213.txt     \n",
            "  inflating: Collection5/214.ann     \n",
            "  inflating: Collection5/214.txt     \n",
            "  inflating: Collection5/215.ann     \n",
            "  inflating: Collection5/215.txt     \n",
            "  inflating: Collection5/216.ann     \n",
            "  inflating: Collection5/216.txt     \n",
            "  inflating: Collection5/217.ann     \n",
            "  inflating: Collection5/217.txt     \n",
            "  inflating: Collection5/218.ann     \n",
            "  inflating: Collection5/218.txt     \n",
            "  inflating: Collection5/219.ann     \n",
            "  inflating: Collection5/219.txt     \n",
            "  inflating: Collection5/21_11_12c.ann  \n",
            "  inflating: Collection5/21_11_12c.txt  \n",
            "  inflating: Collection5/21_11_12h.ann  \n",
            "  inflating: Collection5/21_11_12h.txt  \n",
            "  inflating: Collection5/21_11_12i.ann  \n",
            "  inflating: Collection5/21_11_12i.txt  \n",
            "  inflating: Collection5/21_11_12j.ann  \n",
            "  inflating: Collection5/21_11_12j.txt  \n",
            "  inflating: Collection5/220.ann     \n",
            "  inflating: Collection5/220.txt     \n",
            "  inflating: Collection5/221.ann     \n",
            "  inflating: Collection5/221.txt     \n",
            "  inflating: Collection5/222.ann     \n",
            "  inflating: Collection5/222.txt     \n",
            "  inflating: Collection5/223.ann     \n",
            "  inflating: Collection5/223.txt     \n",
            "  inflating: Collection5/224.ann     \n",
            "  inflating: Collection5/224.txt     \n",
            "  inflating: Collection5/225.ann     \n",
            "  inflating: Collection5/225.txt     \n",
            "  inflating: Collection5/226.ann     \n",
            "  inflating: Collection5/226.txt     \n",
            "  inflating: Collection5/227.ann     \n",
            "  inflating: Collection5/227.txt     \n",
            "  inflating: Collection5/228.ann     \n",
            "  inflating: Collection5/228.txt     \n",
            "  inflating: Collection5/229.ann     \n",
            "  inflating: Collection5/229.txt     \n",
            "  inflating: Collection5/22_11_12a.ann  \n",
            "  inflating: Collection5/22_11_12a.txt  \n",
            "  inflating: Collection5/22_11_12c.ann  \n",
            "  inflating: Collection5/22_11_12c.txt  \n",
            "  inflating: Collection5/22_11_12d.ann  \n",
            "  inflating: Collection5/22_11_12d.txt  \n",
            "  inflating: Collection5/22_11_12g.ann  \n",
            "  inflating: Collection5/22_11_12g.txt  \n",
            "  inflating: Collection5/22_11_12h.ann  \n",
            "  inflating: Collection5/22_11_12h.txt  \n",
            "  inflating: Collection5/22_11_12i.ann  \n",
            "  inflating: Collection5/22_11_12i.txt  \n",
            "  inflating: Collection5/22_11_12j.ann  \n",
            "  inflating: Collection5/22_11_12j.txt  \n",
            "  inflating: Collection5/230.ann     \n",
            "  inflating: Collection5/230.txt     \n",
            "  inflating: Collection5/231.ann     \n",
            "  inflating: Collection5/231.txt     \n",
            "  inflating: Collection5/232.ann     \n",
            "  inflating: Collection5/232.txt     \n",
            "  inflating: Collection5/233.ann     \n",
            "  inflating: Collection5/233.txt     \n",
            "  inflating: Collection5/234.ann     \n",
            "  inflating: Collection5/234.txt     \n",
            "  inflating: Collection5/235.ann     \n",
            "  inflating: Collection5/235.txt     \n",
            "  inflating: Collection5/236.ann     \n",
            "  inflating: Collection5/236.txt     \n",
            "  inflating: Collection5/237.ann     \n",
            "  inflating: Collection5/237.txt     \n",
            "  inflating: Collection5/238.ann     \n",
            "  inflating: Collection5/238.txt     \n",
            "  inflating: Collection5/239.ann     \n",
            "  inflating: Collection5/239.txt     \n",
            "  inflating: Collection5/23_11_12a.ann  \n",
            "  inflating: Collection5/23_11_12a.txt  \n",
            "  inflating: Collection5/23_11_12b.ann  \n",
            "  inflating: Collection5/23_11_12b.txt  \n",
            "  inflating: Collection5/23_11_12c.ann  \n",
            "  inflating: Collection5/23_11_12c.txt  \n",
            "  inflating: Collection5/23_11_12d.ann  \n",
            "  inflating: Collection5/23_11_12d.txt  \n",
            "  inflating: Collection5/23_11_12e.ann  \n",
            "  inflating: Collection5/23_11_12e.txt  \n",
            "  inflating: Collection5/23_11_12f.ann  \n",
            "  inflating: Collection5/23_11_12f.txt  \n",
            "  inflating: Collection5/240.ann     \n",
            "  inflating: Collection5/240.txt     \n",
            "  inflating: Collection5/241.ann     \n",
            "  inflating: Collection5/241.txt     \n",
            "  inflating: Collection5/242.ann     \n",
            "  inflating: Collection5/242.txt     \n",
            "  inflating: Collection5/243.ann     \n",
            "  inflating: Collection5/243.txt     \n",
            "  inflating: Collection5/244.ann     \n",
            "  inflating: Collection5/244.txt     \n",
            "  inflating: Collection5/245.ann     \n",
            "  inflating: Collection5/245.txt     \n",
            "  inflating: Collection5/246.ann     \n",
            "  inflating: Collection5/246.txt     \n",
            "  inflating: Collection5/247.ann     \n",
            "  inflating: Collection5/247.txt     \n",
            "  inflating: Collection5/248.ann     \n",
            "  inflating: Collection5/248.txt     \n",
            "  inflating: Collection5/249.ann     \n",
            "  inflating: Collection5/249.txt     \n",
            "  inflating: Collection5/250.ann     \n",
            "  inflating: Collection5/250.txt     \n",
            "  inflating: Collection5/251.ann     \n",
            "  inflating: Collection5/251.txt     \n",
            "  inflating: Collection5/252.ann     \n",
            "  inflating: Collection5/252.txt     \n",
            "  inflating: Collection5/253.ann     \n",
            "  inflating: Collection5/253.txt     \n",
            "  inflating: Collection5/254.ann     \n",
            "  inflating: Collection5/254.txt     \n",
            "  inflating: Collection5/255.ann     \n",
            "  inflating: Collection5/255.txt     \n",
            "  inflating: Collection5/256.ann     \n",
            "  inflating: Collection5/256.txt     \n",
            "  inflating: Collection5/257.ann     \n",
            "  inflating: Collection5/257.txt     \n",
            "  inflating: Collection5/258.ann     \n",
            "  inflating: Collection5/258.txt     \n",
            "  inflating: Collection5/259.ann     \n",
            "  inflating: Collection5/259.txt     \n",
            "  inflating: Collection5/25_12_12a.ann  \n",
            "  inflating: Collection5/25_12_12a.txt  \n",
            "  inflating: Collection5/25_12_12c.ann  \n",
            "  inflating: Collection5/25_12_12c.txt  \n",
            "  inflating: Collection5/25_12_12d.ann  \n",
            "  inflating: Collection5/25_12_12d.txt  \n",
            "  inflating: Collection5/25_12_12e.ann  \n",
            "  inflating: Collection5/25_12_12e.txt  \n",
            "  inflating: Collection5/260.ann     \n",
            "  inflating: Collection5/260.txt     \n",
            "  inflating: Collection5/261.ann     \n",
            "  inflating: Collection5/261.txt     \n",
            "  inflating: Collection5/262.ann     \n",
            "  inflating: Collection5/262.txt     \n",
            "  inflating: Collection5/263.ann     \n",
            "  inflating: Collection5/263.txt     \n",
            "  inflating: Collection5/264.ann     \n",
            "  inflating: Collection5/264.txt     \n",
            "  inflating: Collection5/265.ann     \n",
            "  inflating: Collection5/265.txt     \n",
            "  inflating: Collection5/266.ann     \n",
            "  inflating: Collection5/266.txt     \n",
            "  inflating: Collection5/267.ann     \n",
            "  inflating: Collection5/267.txt     \n",
            "  inflating: Collection5/268.ann     \n",
            "  inflating: Collection5/268.txt     \n",
            "  inflating: Collection5/269.ann     \n",
            "  inflating: Collection5/269.txt     \n",
            "  inflating: Collection5/26_11_12b.ann  \n",
            "  inflating: Collection5/26_11_12b.txt  \n",
            "  inflating: Collection5/26_11_12c.ann  \n",
            "  inflating: Collection5/26_11_12c.txt  \n",
            "  inflating: Collection5/26_11_12e.ann  \n",
            "  inflating: Collection5/26_11_12e.txt  \n",
            "  inflating: Collection5/26_11_12f.ann  \n",
            "  inflating: Collection5/26_11_12f.txt  \n",
            "  inflating: Collection5/270.ann     \n",
            "  inflating: Collection5/270.txt     \n",
            "  inflating: Collection5/271.ann     \n",
            "  inflating: Collection5/271.txt     \n",
            "  inflating: Collection5/272.ann     \n",
            "  inflating: Collection5/272.txt     \n",
            "  inflating: Collection5/273.ann     \n",
            "  inflating: Collection5/273.txt     \n",
            "  inflating: Collection5/274.ann     \n",
            "  inflating: Collection5/274.txt     \n",
            "  inflating: Collection5/275.ann     \n",
            "  inflating: Collection5/275.txt     \n",
            "  inflating: Collection5/276.ann     \n",
            "  inflating: Collection5/276.txt     \n",
            "  inflating: Collection5/277.ann     \n",
            "  inflating: Collection5/277.txt     \n",
            "  inflating: Collection5/278.ann     \n",
            "  inflating: Collection5/278.txt     \n",
            "  inflating: Collection5/279.ann     \n",
            "  inflating: Collection5/279.txt     \n",
            "  inflating: Collection5/27_11_12a.ann  \n",
            "  inflating: Collection5/27_11_12a.txt  \n",
            "  inflating: Collection5/27_11_12c.ann  \n",
            "  inflating: Collection5/27_11_12c.txt  \n",
            "  inflating: Collection5/27_11_12d.ann  \n",
            "  inflating: Collection5/27_11_12d.txt  \n",
            "  inflating: Collection5/27_11_12e.ann  \n",
            "  inflating: Collection5/27_11_12e.txt  \n",
            "  inflating: Collection5/27_11_12j.ann  \n",
            "  inflating: Collection5/27_11_12j.txt  \n",
            "  inflating: Collection5/280.ann     \n",
            "  inflating: Collection5/280.txt     \n",
            "  inflating: Collection5/281.ann     \n",
            "  inflating: Collection5/281.txt     \n",
            "  inflating: Collection5/282.ann     \n",
            "  inflating: Collection5/282.txt     \n",
            "  inflating: Collection5/283.ann     \n",
            "  inflating: Collection5/283.txt     \n",
            "  inflating: Collection5/284.ann     \n",
            "  inflating: Collection5/284.txt     \n",
            "  inflating: Collection5/285.ann     \n",
            "  inflating: Collection5/285.txt     \n",
            "  inflating: Collection5/286.ann     \n",
            "  inflating: Collection5/286.txt     \n",
            "  inflating: Collection5/287.ann     \n",
            "  inflating: Collection5/287.txt     \n",
            "  inflating: Collection5/288.ann     \n",
            "  inflating: Collection5/288.txt     \n",
            "  inflating: Collection5/289.ann     \n",
            "  inflating: Collection5/289.txt     \n",
            "  inflating: Collection5/28_11_12a.ann  \n",
            "  inflating: Collection5/28_11_12a.txt  \n",
            "  inflating: Collection5/28_11_12f.ann  \n",
            "  inflating: Collection5/28_11_12f.txt  \n",
            "  inflating: Collection5/28_11_12g.ann  \n",
            "  inflating: Collection5/28_11_12g.txt  \n",
            "  inflating: Collection5/28_11_12h.ann  \n",
            "  inflating: Collection5/28_11_12h.txt  \n",
            "  inflating: Collection5/28_11_12i.ann  \n",
            "  inflating: Collection5/28_11_12i.txt  \n",
            "  inflating: Collection5/28_11_12j.ann  \n",
            "  inflating: Collection5/28_11_12j.txt  \n",
            "  inflating: Collection5/290.ann     \n",
            "  inflating: Collection5/290.txt     \n",
            "  inflating: Collection5/291.ann     \n",
            "  inflating: Collection5/291.txt     \n",
            "  inflating: Collection5/292.ann     \n",
            "  inflating: Collection5/292.txt     \n",
            "  inflating: Collection5/293.ann     \n",
            "  inflating: Collection5/293.txt     \n",
            "  inflating: Collection5/294.ann     \n",
            "  inflating: Collection5/294.txt     \n",
            "  inflating: Collection5/295.ann     \n",
            "  inflating: Collection5/295.txt     \n",
            "  inflating: Collection5/296.ann     \n",
            "  inflating: Collection5/296.txt     \n",
            "  inflating: Collection5/297.ann     \n",
            "  inflating: Collection5/297.txt     \n",
            "  inflating: Collection5/298.ann     \n",
            "  inflating: Collection5/298.txt     \n",
            "  inflating: Collection5/299.ann     \n",
            "  inflating: Collection5/299.txt     \n",
            "  inflating: Collection5/29_11_12a.ann  \n",
            "  inflating: Collection5/29_11_12a.txt  \n",
            "  inflating: Collection5/29_11_12b.ann  \n",
            "  inflating: Collection5/29_11_12b.txt  \n",
            "  inflating: Collection5/300.ann     \n",
            "  inflating: Collection5/300.txt     \n",
            "  inflating: Collection5/301.ann     \n",
            "  inflating: Collection5/301.txt     \n",
            "  inflating: Collection5/302.ann     \n",
            "  inflating: Collection5/302.txt     \n",
            "  inflating: Collection5/303.ann     \n",
            "  inflating: Collection5/303.txt     \n",
            "  inflating: Collection5/304.ann     \n",
            "  inflating: Collection5/304.txt     \n",
            "  inflating: Collection5/305.ann     \n",
            "  inflating: Collection5/305.txt     \n",
            "  inflating: Collection5/306.ann     \n",
            "  inflating: Collection5/306.txt     \n",
            "  inflating: Collection5/307.ann     \n",
            "  inflating: Collection5/307.txt     \n",
            "  inflating: Collection5/308.ann     \n",
            "  inflating: Collection5/308.txt     \n",
            "  inflating: Collection5/309.ann     \n",
            "  inflating: Collection5/309.txt     \n",
            "  inflating: Collection5/30_11_12b.ann  \n",
            "  inflating: Collection5/30_11_12b.txt  \n",
            "  inflating: Collection5/30_11_12h.ann  \n",
            "  inflating: Collection5/30_11_12h.txt  \n",
            "  inflating: Collection5/30_11_12i.ann  \n",
            "  inflating: Collection5/30_11_12i.txt  \n",
            "  inflating: Collection5/310.ann     \n",
            "  inflating: Collection5/310.txt     \n",
            "  inflating: Collection5/311.ann     \n",
            "  inflating: Collection5/311.txt     \n",
            "  inflating: Collection5/312.ann     \n",
            "  inflating: Collection5/312.txt     \n",
            "  inflating: Collection5/313.ann     \n",
            "  inflating: Collection5/313.txt     \n",
            "  inflating: Collection5/314.ann     \n",
            "  inflating: Collection5/314.txt     \n",
            "  inflating: Collection5/315.ann     \n",
            "  inflating: Collection5/315.txt     \n",
            "  inflating: Collection5/316.ann     \n",
            "  inflating: Collection5/316.txt     \n",
            "  inflating: Collection5/317.ann     \n",
            "  inflating: Collection5/317.txt     \n",
            "  inflating: Collection5/318.ann     \n",
            "  inflating: Collection5/318.txt     \n",
            "  inflating: Collection5/319.ann     \n",
            "  inflating: Collection5/319.txt     \n",
            "  inflating: Collection5/320.ann     \n",
            "  inflating: Collection5/320.txt     \n",
            "  inflating: Collection5/321.ann     \n",
            "  inflating: Collection5/321.txt     \n",
            "  inflating: Collection5/322.ann     \n",
            "  inflating: Collection5/322.txt     \n",
            "  inflating: Collection5/323.ann     \n",
            "  inflating: Collection5/323.txt     \n",
            "  inflating: Collection5/324.ann     \n",
            "  inflating: Collection5/324.txt     \n",
            "  inflating: Collection5/325.ann     \n",
            "  inflating: Collection5/325.txt     \n",
            "  inflating: Collection5/326.ann     \n",
            "  inflating: Collection5/326.txt     \n",
            "  inflating: Collection5/327.ann     \n",
            "  inflating: Collection5/327.txt     \n",
            "  inflating: Collection5/328.ann     \n",
            "  inflating: Collection5/328.txt     \n",
            "  inflating: Collection5/329.ann     \n",
            "  inflating: Collection5/329.txt     \n",
            "  inflating: Collection5/330.ann     \n",
            "  inflating: Collection5/330.txt     \n",
            "  inflating: Collection5/331.ann     \n",
            "  inflating: Collection5/331.txt     \n",
            "  inflating: Collection5/332.ann     \n",
            "  inflating: Collection5/332.txt     \n",
            "  inflating: Collection5/333.ann     \n",
            "  inflating: Collection5/333.txt     \n",
            "  inflating: Collection5/334.ann     \n",
            "  inflating: Collection5/334.txt     \n",
            "  inflating: Collection5/335.ann     \n",
            "  inflating: Collection5/335.txt     \n",
            "  inflating: Collection5/336.ann     \n",
            "  inflating: Collection5/336.txt     \n",
            "  inflating: Collection5/337.ann     \n",
            "  inflating: Collection5/337.txt     \n",
            "  inflating: Collection5/338.ann     \n",
            "  inflating: Collection5/338.txt     \n",
            "  inflating: Collection5/339.ann     \n",
            "  inflating: Collection5/339.txt     \n",
            "  inflating: Collection5/340.ann     \n",
            "  inflating: Collection5/340.txt     \n",
            "  inflating: Collection5/341.ann     \n",
            "  inflating: Collection5/341.txt     \n",
            "  inflating: Collection5/342.ann     \n",
            "  inflating: Collection5/342.txt     \n",
            "  inflating: Collection5/343.ann     \n",
            "  inflating: Collection5/343.txt     \n",
            "  inflating: Collection5/344.ann     \n",
            "  inflating: Collection5/344.txt     \n",
            "  inflating: Collection5/345.ann     \n",
            "  inflating: Collection5/345.txt     \n",
            "  inflating: Collection5/346.ann     \n",
            "  inflating: Collection5/346.txt     \n",
            "  inflating: Collection5/347.ann     \n",
            "  inflating: Collection5/347.txt     \n",
            "  inflating: Collection5/348.ann     \n",
            "  inflating: Collection5/348.txt     \n",
            "  inflating: Collection5/349.ann     \n",
            "  inflating: Collection5/349.txt     \n",
            "  inflating: Collection5/350.ann     \n",
            "  inflating: Collection5/350.txt     \n",
            "  inflating: Collection5/351.ann     \n",
            "  inflating: Collection5/351.txt     \n",
            "  inflating: Collection5/352.ann     \n",
            "  inflating: Collection5/352.txt     \n",
            "  inflating: Collection5/353.ann     \n",
            "  inflating: Collection5/353.txt     \n",
            "  inflating: Collection5/354.ann     \n",
            "  inflating: Collection5/354.txt     \n",
            "  inflating: Collection5/355.ann     \n",
            "  inflating: Collection5/355.txt     \n",
            "  inflating: Collection5/356.ann     \n",
            "  inflating: Collection5/356.txt     \n",
            "  inflating: Collection5/357.ann     \n",
            "  inflating: Collection5/357.txt     \n",
            "  inflating: Collection5/358.ann     \n",
            "  inflating: Collection5/358.txt     \n",
            "  inflating: Collection5/359.ann     \n",
            "  inflating: Collection5/359.txt     \n",
            "  inflating: Collection5/360.ann     \n",
            "  inflating: Collection5/360.txt     \n",
            "  inflating: Collection5/361.ann     \n",
            "  inflating: Collection5/361.txt     \n",
            "  inflating: Collection5/362.ann     \n",
            "  inflating: Collection5/362.txt     \n",
            "  inflating: Collection5/363.ann     \n",
            "  inflating: Collection5/363.txt     \n",
            "  inflating: Collection5/364.ann     \n",
            "  inflating: Collection5/364.txt     \n",
            "  inflating: Collection5/365.ann     \n",
            "  inflating: Collection5/365.txt     \n",
            "  inflating: Collection5/366.ann     \n",
            "  inflating: Collection5/366.txt     \n",
            "  inflating: Collection5/367.ann     \n",
            "  inflating: Collection5/367.txt     \n",
            "  inflating: Collection5/368.ann     \n",
            "  inflating: Collection5/368.txt     \n",
            "  inflating: Collection5/369.ann     \n",
            "  inflating: Collection5/369.txt     \n",
            "  inflating: Collection5/370.ann     \n",
            "  inflating: Collection5/370.txt     \n",
            "  inflating: Collection5/371.ann     \n",
            "  inflating: Collection5/371.txt     \n",
            "  inflating: Collection5/372.ann     \n",
            "  inflating: Collection5/372.txt     \n",
            "  inflating: Collection5/373.ann     \n",
            "  inflating: Collection5/373.txt     \n",
            "  inflating: Collection5/374.ann     \n",
            "  inflating: Collection5/374.txt     \n",
            "  inflating: Collection5/375.ann     \n",
            "  inflating: Collection5/375.txt     \n",
            "  inflating: Collection5/376.ann     \n",
            "  inflating: Collection5/376.txt     \n",
            "  inflating: Collection5/377.ann     \n",
            "  inflating: Collection5/377.txt     \n",
            "  inflating: Collection5/378.ann     \n",
            "  inflating: Collection5/378.txt     \n",
            "  inflating: Collection5/379.ann     \n",
            "  inflating: Collection5/379.txt     \n",
            "  inflating: Collection5/380.ann     \n",
            "  inflating: Collection5/380.txt     \n",
            "  inflating: Collection5/381.ann     \n",
            "  inflating: Collection5/381.txt     \n",
            "  inflating: Collection5/382.ann     \n",
            "  inflating: Collection5/382.txt     \n",
            "  inflating: Collection5/383.ann     \n",
            "  inflating: Collection5/383.txt     \n",
            "  inflating: Collection5/384.ann     \n",
            "  inflating: Collection5/384.txt     \n",
            "  inflating: Collection5/385.ann     \n",
            "  inflating: Collection5/385.txt     \n",
            "  inflating: Collection5/386.ann     \n",
            "  inflating: Collection5/386.txt     \n",
            "  inflating: Collection5/387.ann     \n",
            "  inflating: Collection5/387.txt     \n",
            "  inflating: Collection5/388.ann     \n",
            "  inflating: Collection5/388.txt     \n",
            "  inflating: Collection5/389.ann     \n",
            "  inflating: Collection5/389.txt     \n",
            "  inflating: Collection5/390.ann     \n",
            "  inflating: Collection5/390.txt     \n",
            "  inflating: Collection5/391.ann     \n",
            "  inflating: Collection5/391.txt     \n",
            "  inflating: Collection5/392.ann     \n",
            "  inflating: Collection5/392.txt     \n",
            "  inflating: Collection5/393.ann     \n",
            "  inflating: Collection5/393.txt     \n",
            "  inflating: Collection5/394.ann     \n",
            "  inflating: Collection5/394.txt     \n",
            "  inflating: Collection5/395.ann     \n",
            "  inflating: Collection5/395.txt     \n",
            "  inflating: Collection5/396.ann     \n",
            "  inflating: Collection5/396.txt     \n",
            "  inflating: Collection5/397.ann     \n",
            "  inflating: Collection5/397.txt     \n",
            "  inflating: Collection5/398.ann     \n",
            "  inflating: Collection5/398.txt     \n",
            "  inflating: Collection5/399.ann     \n",
            "  inflating: Collection5/399.txt     \n",
            "  inflating: Collection5/400.ann     \n",
            "  inflating: Collection5/400.txt     \n",
            "  inflating: Collection5/401.ann     \n",
            "  inflating: Collection5/401.txt     \n",
            "  inflating: Collection5/402.ann     \n",
            "  inflating: Collection5/402.txt     \n",
            "  inflating: Collection5/403.ann     \n",
            "  inflating: Collection5/403.txt     \n",
            "  inflating: Collection5/404.ann     \n",
            "  inflating: Collection5/404.txt     \n",
            "  inflating: Collection5/405.ann     \n",
            "  inflating: Collection5/405.txt     \n",
            "  inflating: Collection5/406.ann     \n",
            "  inflating: Collection5/406.txt     \n",
            "  inflating: Collection5/407.ann     \n",
            "  inflating: Collection5/407.txt     \n",
            "  inflating: Collection5/408.ann     \n",
            "  inflating: Collection5/408.txt     \n",
            "  inflating: Collection5/409.ann     \n",
            "  inflating: Collection5/409.txt     \n",
            "  inflating: Collection5/410.ann     \n",
            "  inflating: Collection5/410.txt     \n",
            "  inflating: Collection5/411.ann     \n",
            "  inflating: Collection5/411.txt     \n",
            "  inflating: Collection5/412.ann     \n",
            "  inflating: Collection5/412.txt     \n",
            "  inflating: Collection5/413.ann     \n",
            "  inflating: Collection5/413.txt     \n",
            "  inflating: Collection5/414.ann     \n",
            "  inflating: Collection5/414.txt     \n",
            "  inflating: Collection5/415.ann     \n",
            "  inflating: Collection5/415.txt     \n",
            "  inflating: Collection5/416.ann     \n",
            "  inflating: Collection5/416.txt     \n",
            "  inflating: Collection5/417.ann     \n",
            "  inflating: Collection5/417.txt     \n",
            "  inflating: Collection5/418.ann     \n",
            "  inflating: Collection5/418.txt     \n",
            "  inflating: Collection5/419.ann     \n",
            "  inflating: Collection5/419.txt     \n",
            "  inflating: Collection5/420.ann     \n",
            "  inflating: Collection5/420.txt     \n",
            "  inflating: Collection5/421.ann     \n",
            "  inflating: Collection5/421.txt     \n",
            "  inflating: Collection5/422.ann     \n",
            "  inflating: Collection5/422.txt     \n",
            "  inflating: Collection5/423.ann     \n",
            "  inflating: Collection5/423.txt     \n",
            "  inflating: Collection5/424.ann     \n",
            "  inflating: Collection5/424.txt     \n",
            "  inflating: Collection5/425.ann     \n",
            "  inflating: Collection5/425.txt     \n",
            "  inflating: Collection5/426.ann     \n",
            "  inflating: Collection5/426.txt     \n",
            "  inflating: Collection5/427.ann     \n",
            "  inflating: Collection5/427.txt     \n",
            "  inflating: Collection5/428.ann     \n",
            "  inflating: Collection5/428.txt     \n",
            "  inflating: Collection5/429.ann     \n",
            "  inflating: Collection5/429.txt     \n",
            "  inflating: Collection5/430.ann     \n",
            "  inflating: Collection5/430.txt     \n",
            "  inflating: Collection5/431.ann     \n",
            "  inflating: Collection5/431.txt     \n",
            "  inflating: Collection5/432.ann     \n",
            "  inflating: Collection5/432.txt     \n",
            "  inflating: Collection5/433.ann     \n",
            "  inflating: Collection5/433.txt     \n",
            "  inflating: Collection5/434.ann     \n",
            "  inflating: Collection5/434.txt     \n",
            "  inflating: Collection5/435.ann     \n",
            "  inflating: Collection5/435.txt     \n",
            "  inflating: Collection5/436.ann     \n",
            "  inflating: Collection5/436.txt     \n",
            "  inflating: Collection5/437.ann     \n",
            "  inflating: Collection5/437.txt     \n",
            "  inflating: Collection5/438.ann     \n",
            "  inflating: Collection5/438.txt     \n",
            "  inflating: Collection5/439.ann     \n",
            "  inflating: Collection5/439.txt     \n",
            "  inflating: Collection5/440.ann     \n",
            "  inflating: Collection5/440.txt     \n",
            "  inflating: Collection5/441.ann     \n",
            "  inflating: Collection5/441.txt     \n",
            "  inflating: Collection5/442.ann     \n",
            "  inflating: Collection5/442.txt     \n",
            "  inflating: Collection5/443.ann     \n",
            "  inflating: Collection5/443.txt     \n",
            "  inflating: Collection5/444.ann     \n",
            "  inflating: Collection5/444.txt     \n",
            "  inflating: Collection5/445.ann     \n",
            "  inflating: Collection5/445.txt     \n",
            "  inflating: Collection5/446.ann     \n",
            "  inflating: Collection5/446.txt     \n",
            "  inflating: Collection5/447.ann     \n",
            "  inflating: Collection5/447.txt     \n",
            "  inflating: Collection5/448.ann     \n",
            "  inflating: Collection5/448.txt     \n",
            "  inflating: Collection5/449.ann     \n",
            "  inflating: Collection5/449.txt     \n",
            "  inflating: Collection5/450.ann     \n",
            "  inflating: Collection5/450.txt     \n",
            "  inflating: Collection5/451.ann     \n",
            "  inflating: Collection5/451.txt     \n",
            "  inflating: Collection5/452.ann     \n",
            "  inflating: Collection5/452.txt     \n",
            "  inflating: Collection5/453.ann     \n",
            "  inflating: Collection5/453.txt     \n",
            "  inflating: Collection5/454.ann     \n",
            "  inflating: Collection5/454.txt     \n",
            "  inflating: Collection5/455.ann     \n",
            "  inflating: Collection5/455.txt     \n",
            "  inflating: Collection5/457.ann     \n",
            "  inflating: Collection5/457.txt     \n",
            "  inflating: Collection5/458.ann     \n",
            "  inflating: Collection5/458.txt     \n",
            "  inflating: Collection5/459.ann     \n",
            "  inflating: Collection5/459.txt     \n",
            "  inflating: Collection5/460.ann     \n",
            "  inflating: Collection5/460.txt     \n",
            "  inflating: Collection5/461.ann     \n",
            "  inflating: Collection5/461.txt     \n",
            "  inflating: Collection5/462.ann     \n",
            "  inflating: Collection5/462.txt     \n",
            "  inflating: Collection5/463.ann     \n",
            "  inflating: Collection5/463.txt     \n",
            "  inflating: Collection5/464.ann     \n",
            "  inflating: Collection5/464.txt     \n",
            "  inflating: Collection5/465.ann     \n",
            "  inflating: Collection5/465.txt     \n",
            "  inflating: Collection5/466.ann     \n",
            "  inflating: Collection5/466.txt     \n",
            "  inflating: Collection5/467.ann     \n",
            "  inflating: Collection5/467.txt     \n",
            "  inflating: Collection5/468.ann     \n",
            "  inflating: Collection5/468.txt     \n",
            "  inflating: Collection5/469.ann     \n",
            "  inflating: Collection5/469.txt     \n",
            "  inflating: Collection5/470.ann     \n",
            "  inflating: Collection5/470.txt     \n",
            "  inflating: Collection5/471.ann     \n",
            "  inflating: Collection5/471.txt     \n",
            "  inflating: Collection5/472.ann     \n",
            "  inflating: Collection5/472.txt     \n",
            "  inflating: Collection5/473.ann     \n",
            "  inflating: Collection5/473.txt     \n",
            "  inflating: Collection5/474.ann     \n",
            "  inflating: Collection5/474.txt     \n",
            "  inflating: Collection5/475.ann     \n",
            "  inflating: Collection5/475.txt     \n",
            "  inflating: Collection5/476.ann     \n",
            "  inflating: Collection5/476.txt     \n",
            "  inflating: Collection5/477.ann     \n",
            "  inflating: Collection5/477.txt     \n",
            "  inflating: Collection5/478.ann     \n",
            "  inflating: Collection5/478.txt     \n",
            "  inflating: Collection5/479.ann     \n",
            "  inflating: Collection5/479.txt     \n",
            "  inflating: Collection5/480.ann     \n",
            "  inflating: Collection5/480.txt     \n",
            "  inflating: Collection5/481.ann     \n",
            "  inflating: Collection5/481.txt     \n",
            "  inflating: Collection5/482.ann     \n",
            "  inflating: Collection5/482.txt     \n",
            "  inflating: Collection5/483.ann     \n",
            "  inflating: Collection5/483.txt     \n",
            "  inflating: Collection5/484.ann     \n",
            "  inflating: Collection5/484.txt     \n",
            "  inflating: Collection5/485.ann     \n",
            "  inflating: Collection5/485.txt     \n",
            "  inflating: Collection5/486.ann     \n",
            "  inflating: Collection5/486.txt     \n",
            "  inflating: Collection5/487.ann     \n",
            "  inflating: Collection5/487.txt     \n",
            "  inflating: Collection5/488.ann     \n",
            "  inflating: Collection5/488.txt     \n",
            "  inflating: Collection5/489.ann     \n",
            "  inflating: Collection5/489.txt     \n",
            "  inflating: Collection5/490.ann     \n",
            "  inflating: Collection5/490.txt     \n",
            "  inflating: Collection5/491.ann     \n",
            "  inflating: Collection5/491.txt     \n",
            "  inflating: Collection5/492.ann     \n",
            "  inflating: Collection5/492.txt     \n",
            "  inflating: Collection5/493.ann     \n",
            "  inflating: Collection5/493.txt     \n",
            "  inflating: Collection5/494.ann     \n",
            "  inflating: Collection5/494.txt     \n",
            "  inflating: Collection5/495.ann     \n",
            "  inflating: Collection5/495.txt     \n",
            "  inflating: Collection5/496.ann     \n",
            "  inflating: Collection5/496.txt     \n",
            "  inflating: Collection5/497.ann     \n",
            "  inflating: Collection5/497.txt     \n",
            "  inflating: Collection5/498.ann     \n",
            "  inflating: Collection5/498.txt     \n",
            "  inflating: Collection5/499.ann     \n",
            "  inflating: Collection5/499.txt     \n",
            "  inflating: Collection5/500.ann     \n",
            "  inflating: Collection5/500.txt     \n",
            "  inflating: Collection5/501.ann     \n",
            "  inflating: Collection5/501.txt     \n",
            "  inflating: Collection5/502.ann     \n",
            "  inflating: Collection5/502.txt     \n",
            "  inflating: Collection5/503.ann     \n",
            "  inflating: Collection5/503.txt     \n",
            "  inflating: Collection5/504.ann     \n",
            "  inflating: Collection5/504.txt     \n",
            "  inflating: Collection5/505.ann     \n",
            "  inflating: Collection5/505.txt     \n",
            "  inflating: Collection5/506.ann     \n",
            "  inflating: Collection5/506.txt     \n",
            "  inflating: Collection5/507.ann     \n",
            "  inflating: Collection5/507.txt     \n",
            "  inflating: Collection5/508.ann     \n",
            "  inflating: Collection5/508.txt     \n",
            "  inflating: Collection5/509.ann     \n",
            "  inflating: Collection5/509.txt     \n",
            "  inflating: Collection5/510.ann     \n",
            "  inflating: Collection5/510.txt     \n",
            "  inflating: Collection5/511.ann     \n",
            "  inflating: Collection5/511.txt     \n",
            "  inflating: Collection5/512.ann     \n",
            "  inflating: Collection5/512.txt     \n",
            "  inflating: Collection5/513.ann     \n",
            "  inflating: Collection5/513.txt     \n",
            "  inflating: Collection5/514.ann     \n",
            "  inflating: Collection5/514.txt     \n",
            "  inflating: Collection5/515.ann     \n",
            "  inflating: Collection5/515.txt     \n",
            "  inflating: Collection5/516.ann     \n",
            "  inflating: Collection5/516.txt     \n",
            "  inflating: Collection5/517.ann     \n",
            "  inflating: Collection5/517.txt     \n",
            "  inflating: Collection5/518.ann     \n",
            "  inflating: Collection5/518.txt     \n",
            "  inflating: Collection5/519.ann     \n",
            "  inflating: Collection5/519.txt     \n",
            "  inflating: Collection5/520.ann     \n",
            "  inflating: Collection5/520.txt     \n",
            "  inflating: Collection5/521.ann     \n",
            "  inflating: Collection5/521.txt     \n",
            "  inflating: Collection5/522.ann     \n",
            "  inflating: Collection5/522.txt     \n",
            "  inflating: Collection5/523.ann     \n",
            "  inflating: Collection5/523.txt     \n",
            "  inflating: Collection5/524.ann     \n",
            "  inflating: Collection5/524.txt     \n",
            "  inflating: Collection5/525.ann     \n",
            "  inflating: Collection5/525.txt     \n",
            "  inflating: Collection5/526.ann     \n",
            "  inflating: Collection5/526.txt     \n",
            "  inflating: Collection5/527.ann     \n",
            "  inflating: Collection5/527.txt     \n",
            "  inflating: Collection5/528.ann     \n",
            "  inflating: Collection5/528.txt     \n",
            "  inflating: Collection5/529.ann     \n",
            "  inflating: Collection5/529.txt     \n",
            "  inflating: Collection5/530.ann     \n",
            "  inflating: Collection5/530.txt     \n",
            "  inflating: Collection5/531.ann     \n",
            "  inflating: Collection5/531.txt     \n",
            "  inflating: Collection5/532.ann     \n",
            "  inflating: Collection5/532.txt     \n",
            "  inflating: Collection5/533 (!).ann  \n",
            "  inflating: Collection5/533 (!).txt  \n",
            "  inflating: Collection5/534.ann     \n",
            "  inflating: Collection5/534.txt     \n",
            "  inflating: Collection5/535.ann     \n",
            "  inflating: Collection5/535.txt     \n",
            "  inflating: Collection5/536.ann     \n",
            "  inflating: Collection5/536.txt     \n",
            "  inflating: Collection5/537.ann     \n",
            "  inflating: Collection5/537.txt     \n",
            "  inflating: Collection5/538.ann     \n",
            "  inflating: Collection5/538.txt     \n",
            "  inflating: Collection5/539.ann     \n",
            "  inflating: Collection5/539.txt     \n",
            "  inflating: Collection5/540.ann     \n",
            "  inflating: Collection5/540.txt     \n",
            "  inflating: Collection5/541.ann     \n",
            "  inflating: Collection5/541.txt     \n",
            "  inflating: Collection5/542.ann     \n",
            "  inflating: Collection5/542.txt     \n",
            "  inflating: Collection5/543.ann     \n",
            "  inflating: Collection5/543.txt     \n",
            "  inflating: Collection5/544.ann     \n",
            "  inflating: Collection5/544.txt     \n",
            "  inflating: Collection5/545.ann     \n",
            "  inflating: Collection5/545.txt     \n",
            "  inflating: Collection5/546.ann     \n",
            "  inflating: Collection5/546.txt     \n",
            "  inflating: Collection5/547.ann     \n",
            "  inflating: Collection5/547.txt     \n",
            "  inflating: Collection5/548.ann     \n",
            "  inflating: Collection5/548.txt     \n",
            "  inflating: Collection5/549.ann     \n",
            "  inflating: Collection5/549.txt     \n",
            "  inflating: Collection5/550.ann     \n",
            "  inflating: Collection5/550.txt     \n",
            "  inflating: Collection5/551.ann     \n",
            "  inflating: Collection5/551.txt     \n",
            "  inflating: Collection5/552.ann     \n",
            "  inflating: Collection5/552.txt     \n",
            "  inflating: Collection5/553.ann     \n",
            "  inflating: Collection5/553.txt     \n",
            "  inflating: Collection5/554.ann     \n",
            "  inflating: Collection5/554.txt     \n",
            "  inflating: Collection5/555 (!).ann  \n",
            "  inflating: Collection5/555 (!).txt  \n",
            "  inflating: Collection5/556.ann     \n",
            "  inflating: Collection5/556.txt     \n",
            "  inflating: Collection5/557.ann     \n",
            "  inflating: Collection5/557.txt     \n",
            "  inflating: Collection5/558.ann     \n",
            "  inflating: Collection5/558.txt     \n",
            "  inflating: Collection5/559.ann     \n",
            "  inflating: Collection5/559.txt     \n",
            "  inflating: Collection5/560.ann     \n",
            "  inflating: Collection5/560.txt     \n",
            "  inflating: Collection5/561.ann     \n",
            "  inflating: Collection5/561.txt     \n",
            "  inflating: Collection5/562.ann     \n",
            "  inflating: Collection5/562.txt     \n",
            "  inflating: Collection5/563.ann     \n",
            "  inflating: Collection5/563.txt     \n",
            "  inflating: Collection5/564.ann     \n",
            "  inflating: Collection5/564.txt     \n",
            "  inflating: Collection5/565.ann     \n",
            "  inflating: Collection5/565.txt     \n",
            "  inflating: Collection5/567.ann     \n",
            "  inflating: Collection5/567.txt     \n",
            "  inflating: Collection5/568.ann     \n",
            "  inflating: Collection5/568.txt     \n",
            "  inflating: Collection5/569.ann     \n",
            "  inflating: Collection5/569.txt     \n",
            "  inflating: Collection5/570.ann     \n",
            "  inflating: Collection5/570.txt     \n",
            "  inflating: Collection5/571.ann     \n",
            "  inflating: Collection5/571.txt     \n",
            "  inflating: Collection5/572.ann     \n",
            "  inflating: Collection5/572.txt     \n",
            "  inflating: Collection5/574.ann     \n",
            "  inflating: Collection5/574.txt     \n",
            "  inflating: Collection5/575.ann     \n",
            "  inflating: Collection5/575.txt     \n",
            "  inflating: Collection5/576.ann     \n",
            "  inflating: Collection5/576.txt     \n",
            "  inflating: Collection5/577.ann     \n",
            "  inflating: Collection5/577.txt     \n",
            "  inflating: Collection5/578.ann     \n",
            "  inflating: Collection5/578.txt     \n",
            "  inflating: Collection5/579.ann     \n",
            "  inflating: Collection5/579.txt     \n",
            "  inflating: Collection5/581.ann     \n",
            "  inflating: Collection5/581.txt     \n",
            "  inflating: Collection5/582.ann     \n",
            "  inflating: Collection5/582.txt     \n",
            "  inflating: Collection5/583.ann     \n",
            "  inflating: Collection5/583.txt     \n",
            "  inflating: Collection5/584 (!).ann  \n",
            "  inflating: Collection5/584 (!).txt  \n",
            "  inflating: Collection5/585.ann     \n",
            "  inflating: Collection5/585.txt     \n",
            "  inflating: Collection5/586.ann     \n",
            "  inflating: Collection5/586.txt     \n",
            "  inflating: Collection5/587.ann     \n",
            "  inflating: Collection5/587.txt     \n",
            "  inflating: Collection5/588.ann     \n",
            "  inflating: Collection5/588.txt     \n",
            "  inflating: Collection5/589.ann     \n",
            "  inflating: Collection5/589.txt     \n",
            "  inflating: Collection5/590.ann     \n",
            "  inflating: Collection5/590.txt     \n",
            "  inflating: Collection5/591.ann     \n",
            "  inflating: Collection5/591.txt     \n",
            "  inflating: Collection5/592.ann     \n",
            "  inflating: Collection5/592.txt     \n",
            "  inflating: Collection5/593.ann     \n",
            "  inflating: Collection5/593.txt     \n",
            "  inflating: Collection5/594.ann     \n",
            "  inflating: Collection5/594.txt     \n",
            "  inflating: Collection5/595.ann     \n",
            "  inflating: Collection5/595.txt     \n",
            "  inflating: Collection5/596.ann     \n",
            "  inflating: Collection5/596.txt     \n",
            "  inflating: Collection5/597.ann     \n",
            "  inflating: Collection5/597.txt     \n",
            "  inflating: Collection5/598 (!).ann  \n",
            "  inflating: Collection5/598 (!).txt  \n",
            "  inflating: Collection5/599.ann     \n",
            "  inflating: Collection5/599.txt     \n",
            "  inflating: Collection5/600.ann     \n",
            "  inflating: Collection5/600.txt     \n",
            "  inflating: Collection5/601.ann     \n",
            "  inflating: Collection5/601.txt     \n",
            "  inflating: Collection5/602.ann     \n",
            "  inflating: Collection5/602.txt     \n",
            "  inflating: Collection5/610.ann     \n",
            "  inflating: Collection5/610.txt     \n",
            "  inflating: Collection5/611.ann     \n",
            "  inflating: Collection5/611.txt     \n",
            "  inflating: Collection5/612.ann     \n",
            "  inflating: Collection5/612.txt     \n",
            "  inflating: Collection5/613.ann     \n",
            "  inflating: Collection5/613.txt     \n",
            "  inflating: Collection5/614.ann     \n",
            "  inflating: Collection5/614.txt     \n",
            "  inflating: Collection5/615.ann     \n",
            "  inflating: Collection5/615.txt     \n",
            "  inflating: Collection5/616.ann     \n",
            "  inflating: Collection5/616.txt     \n",
            "  inflating: Collection5/617.ann     \n",
            "  inflating: Collection5/617.txt     \n",
            "  inflating: Collection5/618.ann     \n",
            "  inflating: Collection5/618.txt     \n",
            "  inflating: Collection5/619.ann     \n",
            "  inflating: Collection5/619.txt     \n",
            "  inflating: Collection5/620.ann     \n",
            "  inflating: Collection5/620.txt     \n",
            "  inflating: Collection5/621.ann     \n",
            "  inflating: Collection5/621.txt     \n",
            "  inflating: Collection5/622.ann     \n",
            "  inflating: Collection5/622.txt     \n",
            "  inflating: Collection5/623.ann     \n",
            "  inflating: Collection5/623.txt     \n",
            "  inflating: Collection5/624.ann     \n",
            "  inflating: Collection5/624.txt     \n",
            "  inflating: Collection5/625.ann     \n",
            "  inflating: Collection5/625.txt     \n",
            "  inflating: Collection5/626.ann     \n",
            "  inflating: Collection5/626.txt     \n",
            "  inflating: Collection5/627.ann     \n",
            "  inflating: Collection5/627.txt     \n",
            "  inflating: Collection5/628.ann     \n",
            "  inflating: Collection5/628.txt     \n",
            "  inflating: Collection5/629.ann     \n",
            "  inflating: Collection5/629.txt     \n",
            "  inflating: Collection5/630.ann     \n",
            "  inflating: Collection5/630.txt     \n",
            "  inflating: Collection5/631.ann     \n",
            "  inflating: Collection5/631.txt     \n",
            "  inflating: Collection5/632.ann     \n",
            "  inflating: Collection5/632.txt     \n",
            "  inflating: Collection5/633.ann     \n",
            "  inflating: Collection5/633.txt     \n",
            "  inflating: Collection5/abdulatipov.ann  \n",
            "  inflating: Collection5/abdulatipov.txt  \n",
            "  inflating: Collection5/artjakov.ann  \n",
            "  inflating: Collection5/artjakov.txt  \n",
            "  inflating: Collection5/Avtovaz.ann  \n",
            "  inflating: Collection5/Avtovaz.txt  \n",
            "  inflating: Collection5/blokhin.ann  \n",
            "  inflating: Collection5/blokhin.txt  \n",
            "  inflating: Collection5/chaves.ann  \n",
            "  inflating: Collection5/chaves.txt  \n",
            "  inflating: Collection5/chirkunov.ann  \n",
            "  inflating: Collection5/chirkunov.txt  \n",
            "  inflating: Collection5/kamchatka.ann  \n",
            "  inflating: Collection5/kamchatka.txt  \n",
            "  inflating: Collection5/klinton.ann  \n",
            "  inflating: Collection5/klinton.txt  \n",
            "  inflating: Collection5/kuleshov.ann  \n",
            "  inflating: Collection5/kuleshov.txt  \n",
            "  inflating: Collection5/last_01.ann  \n",
            "  inflating: Collection5/last_01.txt  \n",
            "  inflating: Collection5/last_02.ann  \n",
            "  inflating: Collection5/last_02.txt  \n",
            "  inflating: Collection5/last_03.ann  \n",
            "  inflating: Collection5/last_03.txt  \n",
            "  inflating: Collection5/last_04.ann  \n",
            "  inflating: Collection5/last_04.txt  \n",
            "  inflating: Collection5/last_05.ann  \n",
            "  inflating: Collection5/last_05.txt  \n",
            "  inflating: Collection5/last_06.ann  \n",
            "  inflating: Collection5/last_06.txt  \n",
            "  inflating: Collection5/last_07_new.ann  \n",
            "  inflating: Collection5/last_07_new.txt  \n",
            "  inflating: Collection5/last_08.ann  \n",
            "  inflating: Collection5/last_08.txt  \n",
            "  inflating: Collection5/last_09.ann  \n",
            "  inflating: Collection5/last_09.txt  \n",
            "  inflating: Collection5/last_10.ann  \n",
            "  inflating: Collection5/last_10.txt  \n",
            "  inflating: Collection5/last_11.ann  \n",
            "  inflating: Collection5/last_11.txt  \n",
            "  inflating: Collection5/last_12.ann  \n",
            "  inflating: Collection5/last_12.txt  \n",
            "  inflating: Collection5/last_13.ann  \n",
            "  inflating: Collection5/last_13.txt  \n",
            "  inflating: Collection5/last_14.ann  \n",
            "  inflating: Collection5/last_14.txt  \n",
            "  inflating: Collection5/last_15.ann  \n",
            "  inflating: Collection5/last_15.txt  \n",
            "  inflating: Collection5/last_16.ann  \n",
            "  inflating: Collection5/last_16.txt  \n",
            "  inflating: Collection5/last_17.ann  \n",
            "  inflating: Collection5/last_17.txt  \n",
            "  inflating: Collection5/last_18.ann  \n",
            "  inflating: Collection5/last_18.txt  \n",
            "  inflating: Collection5/last_19.ann  \n",
            "  inflating: Collection5/last_19.txt  \n",
            "  inflating: Collection5/last_20.ann  \n",
            "  inflating: Collection5/last_20.txt  \n",
            "  inflating: Collection5/last_21.ann  \n",
            "  inflating: Collection5/last_21.txt  \n",
            "  inflating: Collection5/last_22.ann  \n",
            "  inflating: Collection5/last_22.txt  \n",
            "  inflating: Collection5/last_23.ann  \n",
            "  inflating: Collection5/last_23.txt  \n",
            "  inflating: Collection5/last_24.ann  \n",
            "  inflating: Collection5/last_24.txt  \n",
            "  inflating: Collection5/last_25.ann  \n",
            "  inflating: Collection5/last_25.txt  \n",
            "  inflating: Collection5/last_26.ann  \n",
            "  inflating: Collection5/last_26.txt  \n",
            "  inflating: Collection5/last_27.ann  \n",
            "  inflating: Collection5/last_27.txt  \n",
            "  inflating: Collection5/last_28.ann  \n",
            "  inflating: Collection5/last_28.txt  \n",
            "  inflating: Collection5/last_29.ann  \n",
            "  inflating: Collection5/last_29.txt  \n",
            "  inflating: Collection5/last_30_new.ann  \n",
            "  inflating: Collection5/last_30_new.txt  \n",
            "  inflating: Collection5/last_31.ann  \n",
            "  inflating: Collection5/last_31.txt  \n",
            "  inflating: Collection5/last_32.ann  \n",
            "  inflating: Collection5/last_32.txt  \n",
            "  inflating: Collection5/last_33.ann  \n",
            "  inflating: Collection5/last_33.txt  \n",
            "  inflating: Collection5/last_34.ann  \n",
            "  inflating: Collection5/last_34.txt  \n",
            "  inflating: Collection5/last_35.ann  \n",
            "  inflating: Collection5/last_35.txt  \n",
            "  inflating: Collection5/last_36.ann  \n",
            "  inflating: Collection5/last_36.txt  \n",
            "  inflating: Collection5/last_37.ann  \n",
            "  inflating: Collection5/last_37.txt  \n",
            "  inflating: Collection5/last_38.ann  \n",
            "  inflating: Collection5/last_38.txt  \n",
            "  inflating: Collection5/last_39.ann  \n",
            "  inflating: Collection5/last_39.txt  \n",
            "  inflating: Collection5/last_40.ann  \n",
            "  inflating: Collection5/last_40.txt  \n",
            "  inflating: Collection5/last_41.ann  \n",
            "  inflating: Collection5/last_41.txt  \n",
            "  inflating: Collection5/last_42.ann  \n",
            "  inflating: Collection5/last_42.txt  \n",
            "  inflating: Collection5/last_43.ann  \n",
            "  inflating: Collection5/last_43.txt  \n",
            "  inflating: Collection5/last_44.ann  \n",
            "  inflating: Collection5/last_44.txt  \n",
            "  inflating: Collection5/last_45.ann  \n",
            "  inflating: Collection5/last_45.txt  \n",
            "  inflating: Collection5/last_46.ann  \n",
            "  inflating: Collection5/last_46.txt  \n",
            "  inflating: Collection5/last_47.ann  \n",
            "  inflating: Collection5/last_47.txt  \n",
            "  inflating: Collection5/last_48.ann  \n",
            "  inflating: Collection5/last_48.txt  \n",
            "  inflating: Collection5/last_49.ann  \n",
            "  inflating: Collection5/last_49.txt  \n",
            "  inflating: Collection5/last_50.ann  \n",
            "  inflating: Collection5/last_50.txt  \n",
            "  inflating: Collection5/last_51.ann  \n",
            "  inflating: Collection5/last_51.txt  \n",
            "  inflating: Collection5/last_52.ann  \n",
            "  inflating: Collection5/last_52.txt  \n",
            "  inflating: Collection5/last_53.ann  \n",
            "  inflating: Collection5/last_53.txt  \n",
            "  inflating: Collection5/last_54.ann  \n",
            "  inflating: Collection5/last_54.txt  \n",
            "  inflating: Collection5/last_55.ann  \n",
            "  inflating: Collection5/last_55.txt  \n",
            "  inflating: Collection5/last_56.ann  \n",
            "  inflating: Collection5/last_56.txt  \n",
            "  inflating: Collection5/last_57.ann  \n",
            "  inflating: Collection5/last_57.txt  \n",
            "  inflating: Collection5/last_58.ann  \n",
            "  inflating: Collection5/last_58.txt  \n",
            "  inflating: Collection5/last_59.ann  \n",
            "  inflating: Collection5/last_59.txt  \n",
            "  inflating: Collection5/last_60.ann  \n",
            "  inflating: Collection5/last_60.txt  \n",
            "  inflating: Collection5/last_61.ann  \n",
            "  inflating: Collection5/last_61.txt  \n",
            "  inflating: Collection5/last_62.ann  \n",
            "  inflating: Collection5/last_62.txt  \n",
            "  inflating: Collection5/last_63.ann  \n",
            "  inflating: Collection5/last_63.txt  \n",
            "  inflating: Collection5/last_64.ann  \n",
            "  inflating: Collection5/last_64.txt  \n",
            "  inflating: Collection5/last_65.ann  \n",
            "  inflating: Collection5/last_65.txt  \n",
            "  inflating: Collection5/last_66.ann  \n",
            "  inflating: Collection5/last_66.txt  \n",
            "  inflating: Collection5/last_67.ann  \n",
            "  inflating: Collection5/last_67.txt  \n",
            "  inflating: Collection5/last_68.ann  \n",
            "  inflating: Collection5/last_68.txt  \n",
            "  inflating: Collection5/last_69.ann  \n",
            "  inflating: Collection5/last_69.txt  \n",
            "  inflating: Collection5/last_70.ann  \n",
            "  inflating: Collection5/last_70.txt  \n",
            "  inflating: Collection5/last_71.ann  \n",
            "  inflating: Collection5/last_71.txt  \n",
            "  inflating: Collection5/last_72.ann  \n",
            "  inflating: Collection5/last_72.txt  \n",
            "  inflating: Collection5/last_73.ann  \n",
            "  inflating: Collection5/last_73.txt  \n",
            "  inflating: Collection5/last_74.ann  \n",
            "  inflating: Collection5/last_74.txt  \n",
            "  inflating: Collection5/last_75.ann  \n",
            "  inflating: Collection5/last_75.txt  \n",
            "  inflating: Collection5/lenoblast.ann  \n",
            "  inflating: Collection5/lenoblast.txt  \n",
            "  inflating: Collection5/maykl dzhekson.ann  \n",
            "  inflating: Collection5/maykl dzhekson.txt  \n",
            "  inflating: Collection5/mvd.ann     \n",
            "  inflating: Collection5/mvd.txt     \n",
            "  inflating: Collection5/mvd2.ann    \n",
            "  inflating: Collection5/mvd2.txt    \n",
            "  inflating: Collection5/rosobrnadzor.ann  \n",
            "  inflating: Collection5/rosobrnadzor.txt  \n",
            "  inflating: Collection5/ryadovoy chelah.ann  \n",
            "  inflating: Collection5/ryadovoy chelah.txt  \n",
            "  inflating: Collection5/semenenko.ann  \n",
            "  inflating: Collection5/semenenko.txt  \n",
            "  inflating: Collection5/shojgu1.ann  \n",
            "  inflating: Collection5/shojgu1.txt  \n",
            "  inflating: Collection5/shojgu3.ann  \n",
            "  inflating: Collection5/shojgu3.txt  \n",
            "  inflating: Collection5/shojgu4.ann  \n",
            "  inflating: Collection5/shojgu4.txt  \n",
            "  inflating: Collection5/shojgu6.ann  \n",
            "  inflating: Collection5/shojgu6.txt  \n",
            "  inflating: Collection5/si_tzjanpin.ann  \n",
            "  inflating: Collection5/si_tzjanpin.txt  \n",
            "  inflating: Collection5/sobjanin2.ann  \n",
            "  inflating: Collection5/sobjanin2.txt  \n",
            "  inflating: Collection5/turkmenija.ann  \n",
            "  inflating: Collection5/turkmenija.txt  \n",
            "  inflating: Collection5/uchitel.ann  \n",
            "  inflating: Collection5/uchitel.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPxCa2LyH8gW"
      },
      "source": [
        "!rm collection5.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7burz-bD3t4l",
        "outputId": "b89937e3-bc4e-4e12-a0fb-41a8470c13a7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collection5  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEdS2pAS3fod"
      },
      "source": [
        "from corus import load_ne5\n",
        "\n",
        "dir = 'Collection5/'\n",
        "records = load_ne5(dir)\n",
        "rec = next(records)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "almHjFIIOShI",
        "outputId": "ee16e2f9-72db-40e8-cd11-8ccbdc885be4"
      },
      "source": [
        "rec.spans"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Ne5Span(\n",
              "     index='T1',\n",
              "     type='PER',\n",
              "     start=20,\n",
              "     stop=27,\n",
              "     text='Ассанжу'\n",
              " ), Ne5Span(\n",
              "     index='T2',\n",
              "     type='PER',\n",
              "     start=51,\n",
              "     stop=67,\n",
              "     text='Джулиана Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T3',\n",
              "     type='PER',\n",
              "     start=220,\n",
              "     stop=226,\n",
              "     text='Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T4',\n",
              "     type='ORG',\n",
              "     start=514,\n",
              "     stop=523,\n",
              "     text='WikiLeaks'\n",
              " ), Ne5Span(\n",
              "     index='T5',\n",
              "     type='PER',\n",
              "     start=649,\n",
              "     stop=658,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T6',\n",
              "     type='PER',\n",
              "     start=1038,\n",
              "     stop=1047,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T7',\n",
              "     type='PER',\n",
              "     start=1247,\n",
              "     stop=1254,\n",
              "     text='Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T8',\n",
              "     type='GEOPOLIT',\n",
              "     start=1288,\n",
              "     stop=1291,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T9',\n",
              "     type='GEOPOLIT',\n",
              "     start=1316,\n",
              "     stop=1340,\n",
              "     text='Соединенного Королевства'\n",
              " ), Ne5Span(\n",
              "     index='T10',\n",
              "     type='PER',\n",
              "     start=1422,\n",
              "     stop=1432,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T11',\n",
              "     type='GEOPOLIT',\n",
              "     start=1574,\n",
              "     stop=1582,\n",
              "     text='Британии'\n",
              " ), Ne5Span(\n",
              "     index='T12',\n",
              "     type='GEOPOLIT',\n",
              "     start=1623,\n",
              "     stop=1629,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T13',\n",
              "     type='PER',\n",
              "     start=1630,\n",
              "     stop=1639,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T14',\n",
              "     type='PER',\n",
              "     start=1650,\n",
              "     stop=1660,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T15',\n",
              "     type='GEOPOLIT',\n",
              "     start=1717,\n",
              "     stop=1719,\n",
              "     text='ЕС'\n",
              " ), Ne5Span(\n",
              "     index='T16',\n",
              "     type='GEOPOLIT',\n",
              "     start=1722,\n",
              "     stop=1725,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T17',\n",
              "     type='PER',\n",
              "     start=1739,\n",
              "     stop=1749,\n",
              "     text='Д. Ассанжу'\n",
              " ), Ne5Span(\n",
              "     index='T18',\n",
              "     type='GEOPOLIT',\n",
              "     start=1778,\n",
              "     stop=1784,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T19',\n",
              "     type='GEOPOLIT',\n",
              "     start=1787,\n",
              "     stop=1790,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T20',\n",
              "     type='GEOPOLIT',\n",
              "     start=1843,\n",
              "     stop=1846,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T21',\n",
              "     type='PER',\n",
              "     start=2072,\n",
              "     stop=2082,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T22',\n",
              "     type='GEOPOLIT',\n",
              "     start=2255,\n",
              "     stop=2258,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T23',\n",
              "     type='PER',\n",
              "     start=2274,\n",
              "     stop=2284,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T24',\n",
              "     type='GEOPOLIT',\n",
              "     start=2288,\n",
              "     stop=2296,\n",
              "     text='Британии'\n",
              " ), Ne5Span(\n",
              "     index='T25',\n",
              "     type='GEOPOLIT',\n",
              "     start=2299,\n",
              "     stop=2316,\n",
              "     text='Соединенные Штаты'\n",
              " ), Ne5Span(\n",
              "     index='T26',\n",
              "     type='GEOPOLIT',\n",
              "     start=2518,\n",
              "     stop=2526,\n",
              "     text='Британии'\n",
              " ), Ne5Span(\n",
              "     index='T27',\n",
              "     type='GEOPOLIT',\n",
              "     start=2529,\n",
              "     stop=2532,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T28',\n",
              "     type='GEOPOLIT',\n",
              "     start=2844,\n",
              "     stop=2847,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T29',\n",
              "     type='GEOPOLIT',\n",
              "     start=2910,\n",
              "     stop=2918,\n",
              "     text='Британии'\n",
              " ), Ne5Span(\n",
              "     index='T30',\n",
              "     type='GEOPOLIT',\n",
              "     start=3134,\n",
              "     stop=3137,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T31',\n",
              "     type='GEOPOLIT',\n",
              "     start=3156,\n",
              "     stop=3159,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T32',\n",
              "     type='GEOPOLIT',\n",
              "     start=3265,\n",
              "     stop=3273,\n",
              "     text='Британию'\n",
              " ), Ne5Span(\n",
              "     index='T33',\n",
              "     type='ORG',\n",
              "     start=3335,\n",
              "     stop=3356,\n",
              "     text='Друзья экстрадируемых'\n",
              " ), Ne5Span(\n",
              "     index='T34',\n",
              "     type='ORG',\n",
              "     start=3392,\n",
              "     stop=3404,\n",
              "     text='Палате общин'\n",
              " ), Ne5Span(\n",
              "     index='T35',\n",
              "     type='GEOPOLIT',\n",
              "     start=3618,\n",
              "     stop=3621,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T36',\n",
              "     type='GEOPOLIT',\n",
              "     start=3709,\n",
              "     stop=3716,\n",
              "     text='Лондона'\n",
              " ), Ne5Span(\n",
              "     index='T37',\n",
              "     type='GEOPOLIT',\n",
              "     start=3803,\n",
              "     stop=3806,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T38',\n",
              "     type='GEOPOLIT',\n",
              "     start=3944,\n",
              "     stop=3947,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T39',\n",
              "     type='GEOPOLIT',\n",
              "     start=4090,\n",
              "     stop=4093,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T40',\n",
              "     type='PER',\n",
              "     start=4133,\n",
              "     stop=4148,\n",
              "     text='Гэри МакКиннана'\n",
              " ), Ne5Span(\n",
              "     index='T41',\n",
              "     type='ORG',\n",
              "     start=4183,\n",
              "     stop=4192,\n",
              "     text='Пентагона'\n",
              " ), Ne5Span(\n",
              "     index='T42',\n",
              "     type='PER',\n",
              "     start=4304,\n",
              "     stop=4314,\n",
              "     text='Тереза Мэй'\n",
              " ), Ne5Span(\n",
              "     index='T43',\n",
              "     type='PER',\n",
              "     start=4365,\n",
              "     stop=4379,\n",
              "     text='Гэри МакКиннан'\n",
              " ), Ne5Span(\n",
              "     index='T44',\n",
              "     type='GEOPOLIT',\n",
              "     start=4490,\n",
              "     stop=4493,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T45',\n",
              "     type='PER',\n",
              "     start=4502,\n",
              "     stop=4516,\n",
              "     text='Шона Салливана'\n",
              " ), Ne5Span(\n",
              "     index='T46',\n",
              "     type='GEOPOLIT',\n",
              "     start=4539,\n",
              "     stop=4547,\n",
              "     text='Ирландии'\n",
              " ), Ne5Span(\n",
              "     index='T47',\n",
              "     type='GEOPOLIT',\n",
              "     start=4550,\n",
              "     stop=4553,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T48',\n",
              "     type='GEOPOLIT',\n",
              "     start=4699,\n",
              "     stop=4705,\n",
              "     text='Штатам'\n",
              " ), Ne5Span(\n",
              "     index='T49',\n",
              "     type='PER',\n",
              "     start=4750,\n",
              "     stop=4761,\n",
              "     text='Бабар Ахмад'\n",
              " ), Ne5Span(\n",
              "     index='T50',\n",
              "     type='GEOPOLIT',\n",
              "     start=4808,\n",
              "     stop=4811,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T51',\n",
              "     type='ORG',\n",
              "     start=4842,\n",
              "     stop=4869,\n",
              "     text='Министерства внутренних дел'\n",
              " ), Ne5Span(\n",
              "     index='T52',\n",
              "     type='GEOPOLIT',\n",
              "     start=4929,\n",
              "     stop=4935,\n",
              "     text='Штатам'\n",
              " ), Ne5Span(\n",
              "     index='T53',\n",
              "     type='GEOPOLIT',\n",
              "     start=5034,\n",
              "     stop=5057,\n",
              "     text='Соединенное Королевство'\n",
              " ), Ne5Span(\n",
              "     index='T54',\n",
              "     type='PER',\n",
              "     start=5542,\n",
              "     stop=5552,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T55',\n",
              "     type='PER',\n",
              "     start=5608,\n",
              "     stop=5617,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T56',\n",
              "     type='PER',\n",
              "     start=5828,\n",
              "     stop=5838,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T57',\n",
              "     type='GEOPOLIT',\n",
              "     start=5946,\n",
              "     stop=5954,\n",
              "     text='Британии'\n",
              " ), Ne5Span(\n",
              "     index='T58',\n",
              "     type='GEOPOLIT',\n",
              "     start=5957,\n",
              "     stop=5963,\n",
              "     text='Швецию'\n",
              " ), Ne5Span(\n",
              "     index='T59',\n",
              "     type='PER',\n",
              "     start=6064,\n",
              "     stop=6073,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T60',\n",
              "     type='PER',\n",
              "     start=6331,\n",
              "     stop=6341,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T61',\n",
              "     type='PER',\n",
              "     start=6444,\n",
              "     stop=6454,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T62',\n",
              "     type='GEOPOLIT',\n",
              "     start=6563,\n",
              "     stop=6568,\n",
              "     text='Ираке'\n",
              " ), Ne5Span(\n",
              "     index='T63',\n",
              "     type='GEOPOLIT',\n",
              "     start=6780,\n",
              "     stop=6788,\n",
              "     text='Британии'\n",
              " ), Ne5Span(\n",
              "     index='T64',\n",
              "     type='GEOPOLIT',\n",
              "     start=6791,\n",
              "     stop=6794,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T65',\n",
              "     type='GEOPOLIT',\n",
              "     start=6826,\n",
              "     stop=6829,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T66',\n",
              "     type='PER',\n",
              "     start=6878,\n",
              "     stop=6888,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T67',\n",
              "     type='PER',\n",
              "     start=7025,\n",
              "     stop=7035,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T68',\n",
              "     type='PER',\n",
              "     start=7060,\n",
              "     stop=7070,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T69',\n",
              "     type='PER',\n",
              "     start=7154,\n",
              "     stop=7164,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T70',\n",
              "     type='PER',\n",
              "     start=7330,\n",
              "     stop=7340,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T71',\n",
              "     type='PER',\n",
              "     start=7431,\n",
              "     stop=7440,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T72',\n",
              "     type='GEOPOLIT',\n",
              "     start=7542,\n",
              "     stop=7548,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T73',\n",
              "     type='GEOPOLIT',\n",
              "     start=7610,\n",
              "     stop=7613,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T74',\n",
              "     type='PER',\n",
              "     start=7615,\n",
              "     stop=7630,\n",
              "     text='Виктория Нуланд'\n",
              " ), Ne5Span(\n",
              "     index='T75',\n",
              "     type='PER',\n",
              "     start=7633,\n",
              "     stop=7646,\n",
              "     text='Филипп Кроули'\n",
              " ), Ne5Span(\n",
              "     index='T76',\n",
              "     type='PER',\n",
              "     start=7705,\n",
              "     stop=7715,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T77',\n",
              "     type='GEOPOLIT',\n",
              "     start=7718,\n",
              "     stop=7724,\n",
              "     text='Швецию'\n",
              " ), Ne5Span(\n",
              "     index='T78',\n",
              "     type='ORG',\n",
              "     start=7812,\n",
              "     stop=7825,\n",
              "     text='Верховный суд'\n",
              " ), Ne5Span(\n",
              "     index='T79',\n",
              "     type='GEOPOLIT',\n",
              "     start=7826,\n",
              "     stop=7834,\n",
              "     text='Британии'\n",
              " ), Ne5Span(\n",
              "     index='T80',\n",
              "     type='PER',\n",
              "     start=7879,\n",
              "     stop=7888,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T81',\n",
              "     type='GEOPOLIT',\n",
              "     start=7910,\n",
              "     stop=7918,\n",
              "     text='Эквадора'\n",
              " ), Ne5Span(\n",
              "     index='T82',\n",
              "     type='PER',\n",
              "     start=8024,\n",
              "     stop=8034,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T83',\n",
              "     type='GEOPOLIT',\n",
              "     start=8037,\n",
              "     stop=8043,\n",
              "     text='Швецию'\n",
              " ), Ne5Span(\n",
              "     index='T84',\n",
              "     type='GEOPOLIT',\n",
              "     start=8121,\n",
              "     stop=8139,\n",
              "     text='Соединенным Штатам'\n",
              " ), Ne5Span(\n",
              "     index='T85',\n",
              "     type='GEOPOLIT',\n",
              "     start=8192,\n",
              "     stop=8197,\n",
              "     text='Штаты'\n",
              " ), Ne5Span(\n",
              "     index='T86',\n",
              "     type='GEOPOLIT',\n",
              "     start=8359,\n",
              "     stop=8362,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T87',\n",
              "     type='GEOPOLIT',\n",
              "     start=8392,\n",
              "     stop=8398,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T88',\n",
              "     type='PER',\n",
              "     start=8414,\n",
              "     stop=8428,\n",
              "     text='Дэвида Хемлера'\n",
              " ), Ne5Span(\n",
              "     index='T89',\n",
              "     type='GEOPOLIT',\n",
              "     start=8491,\n",
              "     stop=8496,\n",
              "     text='Штаты'\n",
              " ), Ne5Span(\n",
              "     index='T90',\n",
              "     type='GEOPOLIT',\n",
              "     start=8593,\n",
              "     stop=8599,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T91',\n",
              "     type='GEOPOLIT',\n",
              "     start=8855,\n",
              "     stop=8861,\n",
              "     text='Швеция'\n",
              " ), Ne5Span(\n",
              "     index='T92',\n",
              "     type='GEOPOLIT',\n",
              "     start=9066,\n",
              "     stop=9069,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T93',\n",
              "     type='PER',\n",
              "     start=9091,\n",
              "     stop=9106,\n",
              "     text='Дианы Файнштейн'\n",
              " ), Ne5Span(\n",
              "     index='T94',\n",
              "     type='LOC',\n",
              "     start=9120,\n",
              "     stop=9130,\n",
              "     text='Калифорнии'\n",
              " ), Ne5Span(\n",
              "     index='T95',\n",
              "     type='PER',\n",
              "     start=9156,\n",
              "     stop=9166,\n",
              "     text='Д. Ассанжу'\n",
              " ), Ne5Span(\n",
              "     index='T96',\n",
              "     type='PER',\n",
              "     start=9363,\n",
              "     stop=9372,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T97',\n",
              "     type='GEOPOLIT',\n",
              "     start=9385,\n",
              "     stop=9394,\n",
              "     text='Австралии'\n",
              " ), Ne5Span(\n",
              "     index='T98',\n",
              "     type='GEOPOLIT',\n",
              "     start=9401,\n",
              "     stop=9410,\n",
              "     text='Австралия'\n",
              " ), Ne5Span(\n",
              "     index='T99',\n",
              "     type='GEOPOLIT',\n",
              "     start=9454,\n",
              "     stop=9457,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T100',\n",
              "     type='PER',\n",
              "     start=9572,\n",
              "     stop=9582,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T101',\n",
              "     type='GEOPOLIT',\n",
              "     start=9586,\n",
              "     stop=9592,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T102',\n",
              "     type='GEOPOLIT',\n",
              "     start=9595,\n",
              "     stop=9598,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T103',\n",
              "     type='PER',\n",
              "     start=9715,\n",
              "     stop=9725,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T104',\n",
              "     type='GEOPOLIT',\n",
              "     start=9729,\n",
              "     stop=9735,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T105',\n",
              "     type='GEOPOLIT',\n",
              "     start=9738,\n",
              "     stop=9741,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T106',\n",
              "     type='GEOPOLIT',\n",
              "     start=9803,\n",
              "     stop=9809,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T107',\n",
              "     type='GEOPOLIT',\n",
              "     start=9812,\n",
              "     stop=9815,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T108',\n",
              "     type='GEOPOLIT',\n",
              "     start=9892,\n",
              "     stop=9895,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T109',\n",
              "     type='PER',\n",
              "     start=9949,\n",
              "     stop=9959,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T110',\n",
              "     type='GEOPOLIT',\n",
              "     start=10037,\n",
              "     stop=10043,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T111',\n",
              "     type='GEOPOLIT',\n",
              "     start=10046,\n",
              "     stop=10049,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T112',\n",
              "     type='PER',\n",
              "     start=10110,\n",
              "     stop=10128,\n",
              "     text='Эдварда Ли Ховарда'\n",
              " ), Ne5Span(\n",
              "     index='T113',\n",
              "     type='GEOPOLIT',\n",
              "     start=10189,\n",
              "     stop=10195,\n",
              "     text='России'\n",
              " ), Ne5Span(\n",
              "     index='T114',\n",
              "     type='GEOPOLIT',\n",
              "     start=10209,\n",
              "     stop=10212,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T115',\n",
              "     type='PER',\n",
              "     start=10267,\n",
              "     stop=10277,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T116',\n",
              "     type='GEOPOLIT',\n",
              "     start=10354,\n",
              "     stop=10357,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T117',\n",
              "     type='GEOPOLIT',\n",
              "     start=10405,\n",
              "     stop=10411,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T118',\n",
              "     type='GEOPOLIT',\n",
              "     start=10578,\n",
              "     stop=10584,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T119',\n",
              "     type='GEOPOLIT',\n",
              "     start=10599,\n",
              "     stop=10605,\n",
              "     text='Швеция'\n",
              " ), Ne5Span(\n",
              "     index='T120',\n",
              "     type='GEOPOLIT',\n",
              "     start=10886,\n",
              "     stop=10889,\n",
              "     text='США'\n",
              " ), Ne5Span(\n",
              "     index='T121',\n",
              "     type='PER',\n",
              "     start=10921,\n",
              "     stop=10930,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T122',\n",
              "     type='GEOPOLIT',\n",
              "     start=11102,\n",
              "     stop=11108,\n",
              "     text='Швеция'\n",
              " ), Ne5Span(\n",
              "     index='T123',\n",
              "     type='PER',\n",
              "     start=11230,\n",
              "     stop=11240,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T124',\n",
              "     type='GEOPOLIT',\n",
              "     start=11243,\n",
              "     stop=11249,\n",
              "     text='Швеции'\n",
              " ), Ne5Span(\n",
              "     index='T125',\n",
              "     type='PER',\n",
              "     start=11349,\n",
              "     stop=11358,\n",
              "     text='Д. Ассанж'\n",
              " ), Ne5Span(\n",
              "     index='T126',\n",
              "     type='PER',\n",
              "     start=11473,\n",
              "     stop=11483,\n",
              "     text='Д. Ассанжа'\n",
              " ), Ne5Span(\n",
              "     index='T127',\n",
              "     type='GEOPOLIT',\n",
              "     start=11849,\n",
              "     stop=11857,\n",
              "     text='Эквадора'\n",
              " ), Ne5Span(\n",
              "     index='T128',\n",
              "     type='LOC',\n",
              "     start=11860,\n",
              "     stop=11867,\n",
              "     text='Лондоне'\n",
              " )]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRuODJpkIqlv",
        "outputId": "4f8411ad-8ce1-4400-f7b0-a2bd5ce3351b"
      },
      "source": [
        "!pip install razdel"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting razdel\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDdnL6EXJRt9"
      },
      "source": [
        "from razdel import tokenize"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-PIApthNmkD"
      },
      "source": [
        "words_docs = []\n",
        "for ix, rec in enumerate(records):\n",
        "    words = []\n",
        "    for token in tokenize(rec.text):\n",
        "        is_person = False\n",
        "        for person in rec.spans:\n",
        "            if (token.start >= person.start) and (token.stop <= person.stop):\n",
        "                is_person = True\n",
        "                break\n",
        "        words.append([token.text, 'PERSON' if is_person else 'NO_PERSON'])\n",
        "    words_docs.extend(words)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTFbDmaINxtO"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POg6utxhNyZo"
      },
      "source": [
        "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv8sivDxN1je",
        "outputId": "0d56e216-6f44-4426-b4e4-da5fbc00f3bd"
      },
      "source": [
        "df_words['tag'].value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NO_PERSON    217424\n",
              "PERSON        46042\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "kytLnLp5N-Pi",
        "outputId": "3126df11-2937-4aed-862e-d6ab58140a2c"
      },
      "source": [
        "df_words.head(20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>В</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>беспорядках</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>в</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>районе</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>месторождения</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>никеля</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>под</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Воронежем</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ранены</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>полицейские</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>:</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>возбуждено</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>уголовное</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>дело</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Пять</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>сотрудников</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>полиции</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>получили</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ранения</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>в</td>\n",
              "      <td>NO_PERSON</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             word        tag\n",
              "0               В  NO_PERSON\n",
              "1     беспорядках  NO_PERSON\n",
              "2               в  NO_PERSON\n",
              "3          районе  NO_PERSON\n",
              "4   месторождения  NO_PERSON\n",
              "5          никеля  NO_PERSON\n",
              "6             под  NO_PERSON\n",
              "7       Воронежем     PERSON\n",
              "8          ранены  NO_PERSON\n",
              "9     полицейские  NO_PERSON\n",
              "10              :  NO_PERSON\n",
              "11     возбуждено  NO_PERSON\n",
              "12      уголовное  NO_PERSON\n",
              "13           дело  NO_PERSON\n",
              "14           Пять  NO_PERSON\n",
              "15    сотрудников  NO_PERSON\n",
              "16        полиции  NO_PERSON\n",
              "17       получили  NO_PERSON\n",
              "18        ранения  NO_PERSON\n",
              "19              в  NO_PERSON"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skYaNCiC5xM4",
        "outputId": "206feb91-c4cb-43c4-c1e5-2fcf674bb178"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQTtHAmAQqXB",
        "outputId": "a9898216-1d89-4157-b1a6-88cf8dccd4bd"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blxMD7SWQWyb",
        "outputId": "85dcc932-8a02-4de8-d2b2-fe27be1b0dd0"
      },
      "source": [
        "nltk.pos_tag(nltk.word_tokenize(rec.text))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('В.Янукович', 'JJ'),\n",
              " ('сменил', 'NNP'),\n",
              " ('главу', 'NNP'),\n",
              " ('Генштаба', 'NNP'),\n",
              " ('Украины', 'NNP'),\n",
              " ('Президент', 'NNP'),\n",
              " ('Украины', 'NNP'),\n",
              " ('Виктор', 'NNP'),\n",
              " ('Янукович', 'NNP'),\n",
              " ('назначил', 'NNP'),\n",
              " ('новым', 'NNP'),\n",
              " ('начальником', 'NNP'),\n",
              " ('Генштаба', 'NNP'),\n",
              " ('-', ':'),\n",
              " ('главнокомандующим', 'NN'),\n",
              " ('Вооруженных', 'NN'),\n",
              " ('сил', 'NNP'),\n",
              " ('(', '('),\n",
              " ('ВС', 'NNP'),\n",
              " (')', ')'),\n",
              " ('Украины', 'VBD'),\n",
              " ('генерал-лейтенанта', 'JJ'),\n",
              " ('Владимира', 'NNP'),\n",
              " ('Заману', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Об', 'VB'),\n",
              " ('этом', 'JJ'),\n",
              " ('говорится', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('опубликованном', 'NNP'),\n",
              " ('сегодня', 'NNP'),\n",
              " ('указе', 'NNP'),\n",
              " ('главы', 'NNP'),\n",
              " ('государства', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Ранее', 'VB'),\n",
              " ('от', 'JJ'),\n",
              " ('этой', 'NNP'),\n",
              " ('должности', 'NNP'),\n",
              " ('был', 'NNP'),\n",
              " ('освобожден', 'NNP'),\n",
              " ('генерал-полковник', 'JJ'),\n",
              " ('Григорий', 'NNP'),\n",
              " ('Педченко', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Ранее', 'VB'),\n",
              " ('Г.Педченко', 'JJ'),\n",
              " ('заявлял', 'NNP'),\n",
              " ('украинским', 'NNP'),\n",
              " ('СМИ', 'NNP'),\n",
              " ('о', 'NNP'),\n",
              " ('том', 'NNP'),\n",
              " (',', ','),\n",
              " ('что', 'NNP'),\n",
              " ('принял', 'NNP'),\n",
              " ('личное', 'NNP'),\n",
              " ('решение', 'NNP'),\n",
              " ('уйти', 'NNP'),\n",
              " ('из', 'NNP'),\n",
              " ('Генштаба', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('вернуться', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('родную', 'NNP'),\n",
              " ('Одессу', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Владимир', 'VB'),\n",
              " ('Замана', 'JJ'),\n",
              " ('ранее', 'NNP'),\n",
              " ('занимал', 'NNP'),\n",
              " ('должность', 'NNP'),\n",
              " ('первого', 'NNP'),\n",
              " ('заместителя', 'NNP'),\n",
              " ('начальника', 'NNP'),\n",
              " ('Генерального', 'NNP'),\n",
              " ('штаба', 'NNP'),\n",
              " ('Украины', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Напомним', 'NN'),\n",
              " (',', ','),\n",
              " ('в', 'NNP'),\n",
              " ('самом', 'NNP'),\n",
              " ('начале', 'NNP'),\n",
              " ('месяца', 'NNP'),\n",
              " ('на', 'NNP'),\n",
              " ('Украине', 'NNP'),\n",
              " ('сменился', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('министр', 'NNP'),\n",
              " ('обороны', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Вместо', 'VB'),\n",
              " ('Михаила', 'JJ'),\n",
              " ('Ежеля', 'NNP'),\n",
              " (',', ','),\n",
              " ('который', 'NNP'),\n",
              " ('получил', 'NNP'),\n",
              " ('должность', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('администрации', 'NNP'),\n",
              " ('Виктора', 'NNP'),\n",
              " ('Януковича', 'NNP'),\n",
              " (',', ','),\n",
              " ('военное', 'NNP'),\n",
              " ('ведомство', 'NNP'),\n",
              " ('возглавил', 'NNP'),\n",
              " ('Дмитрий', 'NNP'),\n",
              " ('Саламатин', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Пока', 'VB'),\n",
              " ('нет', 'JJ'),\n",
              " ('данных', 'NNP'),\n",
              " (',', ','),\n",
              " ('насколько', 'NNP'),\n",
              " ('связаны', 'NNP'),\n",
              " ('перестановки', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('Министерстве', 'NNP'),\n",
              " ('обороны', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('Генеральном', 'NNP'),\n",
              " ('штабе', 'NNP'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8iCdcs7Q4NR",
        "outputId": "2a793507-aa33-4e11-a293-6082adcb8507"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuC-DC9sQ0gk",
        "outputId": "42985514-c098-405d-ce8c-fe5a0dd90118"
      },
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(rec.text))) if hasattr(chunk, 'label') }\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('Виктора Януковича', 'PERSON'),\n",
              " ('Владимира Заману', 'PERSON'),\n",
              " ('Вооруженных сил', 'PERSON'),\n",
              " ('Генштаба', 'PERSON'),\n",
              " ('Григорий Педченко', 'ORGANIZATION'),\n",
              " ('Дмитрий Саламатин', 'PERSON'),\n",
              " ('Замана', 'PERSON'),\n",
              " ('Михаила Ежеля', 'PERSON'),\n",
              " ('Напомним', 'PERSON'),\n",
              " ('Украине', 'PERSON'),\n",
              " ('Украины Президент Украины Виктор Янукович', 'PERSON')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2kd-emBao1u-",
        "outputId": "ea737e95-c43b-4201-d21a-32dbb99e81b3"
      },
      "source": [
        "# установка deeppavlov\n",
        "\n",
        "!pip uninstall -y tensorflow tensorflow-gpu\n",
        "!pip install numpy scipy librosa unidecode inflect librosa transformers\n",
        "!pip install deeppavlov"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.5.0:\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 21.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
            "Installing collected packages: unidecode, huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2 unidecode-1.2.0\n",
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/87/e77ccc7de09f8c5c4a3d981ff6b1d3811d9978976a30bec9bdf50d667ebb/deeppavlov-0.15.0-py3-none-any.whl (907kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n",
            "Collecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 21.9MB/s \n",
            "\u001b[?25hCollecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 27.4MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/58/2deb24de3c10cc4c0f09639b46f4f4b50059f0fdc785128a57dd9fdce026/Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.41.1)\n",
            "Collecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/53/127cb49435bcf5d841baf8eafa030931c62a9eac577a641f8c2293d23371/numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.5MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 14.4MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 36.1MB/s \n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 30.2MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting uvicorn==0.11.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/5f/2bc87272f189662e129ddcd4807ad3ef83128b4df3a3482335f5f9790f24/uvicorn-0.11.7-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/56/1f652c3f658d2a9fd495d2e988a2da57eabdb6c4b8f4563c2ccbe6a2a8c5/pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 17.2MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/e0/a1b39cdcb2c391f087a1538bc8a6d62a82d0439693192aef541d7b123769/pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 14.5MB/s \n",
            "\u001b[?25hCollecting uvloop==0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/7a/54a80c03b555af21680a2f3692947b43a0d576d90c4c18cace0fee1ccc0e/uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/a4/a48bd4b0d15395362b561df7e7247de87291105eb736a3b2aaffebf437b9/scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 11.1MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n",
            "\u001b[?25hCollecting prometheus-client==0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n",
            "Collecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/fc/12de89822adaa3a60b8cb0139bae75918278999d08e6dff158623abd7cba/ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.0.1)\n",
            "Collecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/c4/dc5b9d50c15af2ee187974a5a0c3f20c06cce6559eea4c065d372e846b6a/aiormq-3.3.1-py3-none-any.whl\n",
            "Collecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 55.6MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 19.0MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.1MB/s \n",
            "\u001b[?25hCollecting httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/2e/485131e3aa113929b425f83854fafc190aa7df716cbeb258c875752f0c6e/httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 36.3MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
            "Collecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 32.0MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.7.4.3)\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
            "Building wheels for collected packages: sacremoses, pytelegrambotapi, overrides, nltk, prometheus-client, starlette\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp37-none-any.whl size=883990 sha256=983b6c72c210219bd9eb0ca4226ca73930b5e18481186188552d944299fca9f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp37-none-any.whl size=47177 sha256=7e2d5d7e41f57a533a8b0e210d5c4a3695f2b7294e5a38e71695eb6a7d1ab62c\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp37-none-any.whl size=5606 sha256=b99fe1b15ca91e240afea2d6a7601c44baf59319ede311c64c87406f276d0f7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449922 sha256=1ec391bfbc01eea0eaaa8ca187fc6e1da3b7d780aafd903c9ed1a50eab36b177\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp37-none-any.whl size=41404 sha256=b78f220a41d6e3929942396a79b2b89d706d94aa6b2be3759a3795e5966c7e13\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp37-none-any.whl size=57254 sha256=661ab9b82b9c475639eeb09335dc0118ab746267d18d4468dc9373411e5b05c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "Successfully built sacremoses pytelegrambotapi overrides nltk prometheus-client starlette\n",
            "\u001b[31mERROR: kapre 0.3.5 requires tensorflow>=2.0.0, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.18.2 has requirement pandas>=1.0, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, pamqp, multidict, idna, yarl, aiormq, aio-pika, requests, pytelegrambotapi, pytz, Cython, overrides, pymorphy2-dicts, dawg-python, pymorphy2, numpy, pymorphy2-dicts-ru, nltk, h5py, rusenttokenize, websockets, uvloop, httptools, h11, uvicorn, pydantic, pandas, scikit-learn, starlette, fastapi, cryptography, pyopenssl, prometheus-client, ruamel.yaml, deeppavlov\n",
            "  Found existing installation: sacremoses 0.0.45\n",
            "    Uninstalling sacremoses-0.0.45:\n",
            "      Successfully uninstalled sacremoses-0.0.45\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: Cython 0.29.23\n",
            "    Uninstalling Cython-0.29.23:\n",
            "      Successfully uninstalled Cython-0.29.23\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: prometheus-client 0.11.0\n",
            "    Uninstalling prometheus-client-0.11.0:\n",
            "      Successfully uninstalled prometheus-client-0.11.0\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-3.4.7 dawg-python-0.7.2 deeppavlov-0.15.0 fastapi-0.47.1 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-5.1.0 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk",
                  "numpy",
                  "pandas",
                  "pytz",
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY96lqBzsZJ_",
        "outputId": "fd3961cd-37dc-4bc8-a388-42173427b289"
      },
      "source": [
        "!python -m deeppavlov install squad_bert\n",
        "!python -m deeppavlov install ner_ontonotes"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-17 10:39:38.140 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_bert.json'\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-pguawkjp\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-pguawkjp\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp37-none-any.whl size=23593 sha256=f6af6d9f3dfd99d65b0b50429d03ded895141e7206462c8f4e03d3f46b6aa4b5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hmwbegxh/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n",
            "Collecting tensorflow==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/81/84fb7a323f9723f81edfc796d89e89aa95a9446ed7353c144195b3a3a3ba/tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 88kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.34.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 35.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (57.2.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.5.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=7b9e4131e4a8d516ecc5c874688b3896da70fd8673ee1c02110ad2dcf1156e9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.13.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorboard, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n",
            "2021-07-17 10:40:12.683 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n",
            "Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.7/dist-packages (1.15.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.34.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (57.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.7.4.3)\n",
            "Collecting gensim==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/93/c6011037f24e3106d13f3be55297bf84ece2bf15b278cc4776339dc52db5/gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 132kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.18.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (5.1.0)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KE7tpVWs1b7"
      },
      "source": [
        "import deeppavlov\n",
        "from deeppavlov import configs, build_model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsegbgCbrzy_",
        "outputId": "fd40fad1-e16d-4b88-a428-6f1a788a12f1"
      },
      "source": [
        "deeppavlov_ner = build_model(configs.ner.ner_bert_ent_and_type_rus, download=True)\n",
        "rus_document = \"Нью-Йорк, США, 30 апреля 2020, 01:01 — REGNUM В администрации президента США Дональда Трампа планируют пройти все этапы создания вакцины от коронавируса в ускоренном темпе и выпустить 100 млн доз до конца 2020 года, передаёт агентство Bloomberg со ссылкой на осведомлённые источники\"\n",
        "deeppavlov_ner([rus_document])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-17 10:42:39.942 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip to /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip\n",
            "100%|██████████| 663M/663M [02:35<00:00, 4.26MB/s]\n",
            "2021-07-17 10:45:17.829 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n",
            "2021-07-17 10:45:28.382 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/kbqa/models/ner_cq_rus.tar.gz to /root/.deeppavlov/models/ner_cq_rus.tar.gz\n",
            "100%|██████████| 1.32G/1.32G [05:32<00:00, 3.96MB/s]\n",
            "2021-07-17 10:51:03.285 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/models/ner_cq_rus.tar.gz archive into /root/.deeppavlov/models/ner_ent_and_type_rus\n",
            "2021-07-17 10:51:24.619 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/kbqa/datasets/entity_and_type_detection_rus.pickle to /root/.deeppavlov/models/entity_and_type_detection_rus.pickle\n",
            "100%|██████████| 2.07M/2.07M [00:01<00:00, 1.15MB/s]\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-17 10:51:33.377 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ent_and_type_rus/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:571: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-17 10:52:05.178 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ent_and_type_rus/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ent_and_type_rus/model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['Нью',\n",
              "   '-',\n",
              "   'Йорк',\n",
              "   ',',\n",
              "   'США',\n",
              "   ',',\n",
              "   '30',\n",
              "   'апреля',\n",
              "   '2020',\n",
              "   ',',\n",
              "   '01',\n",
              "   ':',\n",
              "   '01',\n",
              "   '—',\n",
              "   'REGNUM',\n",
              "   'В',\n",
              "   'администрации',\n",
              "   'президента',\n",
              "   'США',\n",
              "   'Дональда',\n",
              "   'Трампа',\n",
              "   'планируют',\n",
              "   'пройти',\n",
              "   'все',\n",
              "   'этапы',\n",
              "   'создания',\n",
              "   'вакцины',\n",
              "   'от',\n",
              "   'коронавируса',\n",
              "   'в',\n",
              "   'ускоренном',\n",
              "   'темпе',\n",
              "   'и',\n",
              "   'выпустить',\n",
              "   '100',\n",
              "   'млн',\n",
              "   'доз',\n",
              "   'до',\n",
              "   'конца',\n",
              "   '2020',\n",
              "   'года',\n",
              "   ',',\n",
              "   'передаёт',\n",
              "   'агентство',\n",
              "   'Bloomberg',\n",
              "   'со',\n",
              "   'ссылкой',\n",
              "   'на',\n",
              "   'осведомлённые',\n",
              "   'источники']],\n",
              " array([[[9.71761167e-01, 2.64181718e-02, 1.82059826e-03],\n",
              "         [9.60046053e-01, 3.84359621e-02, 1.51804090e-03],\n",
              "         [9.21502233e-01, 7.51483515e-02, 3.34933866e-03],\n",
              "         [9.92245018e-01, 6.89126039e-03, 8.63717811e-04],\n",
              "         [9.87261832e-01, 1.17831351e-02, 9.55077179e-04],\n",
              "         [9.96919036e-01, 2.74484046e-03, 3.36058962e-04],\n",
              "         [9.97517467e-01, 2.30196840e-03, 1.80645322e-04],\n",
              "         [9.95577574e-01, 4.12209751e-03, 3.00363230e-04],\n",
              "         [9.91355956e-01, 8.05664156e-03, 5.87437069e-04],\n",
              "         [9.98594940e-01, 1.27561530e-03, 1.29398570e-04],\n",
              "         [9.98789489e-01, 1.13862741e-03, 7.19211675e-05],\n",
              "         [9.97291386e-01, 2.53513828e-03, 1.73508219e-04],\n",
              "         [9.98374701e-01, 1.53756991e-03, 8.77227576e-05],\n",
              "         [9.97647226e-01, 2.15254142e-03, 2.00248949e-04],\n",
              "         [9.96125996e-01, 3.52644222e-03, 3.47553432e-04],\n",
              "         [9.98647392e-01, 1.18941162e-03, 1.63180783e-04],\n",
              "         [9.94467735e-01, 4.99971071e-03, 5.32494334e-04],\n",
              "         [9.88695621e-01, 1.04803387e-02, 8.23963608e-04],\n",
              "         [9.90075767e-01, 8.98968987e-03, 9.34486161e-04],\n",
              "         [1.60550028e-01, 8.38216543e-01, 1.23350031e-03],\n",
              "         [1.39164224e-01, 8.59113455e-01, 1.72229693e-03],\n",
              "         [9.98087585e-01, 1.73141155e-03, 1.80948962e-04],\n",
              "         [9.98838842e-01, 1.03886123e-03, 1.22317724e-04],\n",
              "         [9.98723567e-01, 1.15420937e-03, 1.22209996e-04],\n",
              "         [9.97251451e-01, 2.43649492e-03, 3.12116492e-04],\n",
              "         [9.96265590e-01, 3.32576130e-03, 4.08622727e-04],\n",
              "         [9.88883674e-01, 1.00314673e-02, 1.08485715e-03],\n",
              "         [9.81114209e-01, 1.81934275e-02, 6.92377449e-04],\n",
              "         [3.06576163e-01, 6.90057814e-01, 3.36598023e-03],\n",
              "         [9.96585727e-01, 3.16357287e-03, 2.50688347e-04],\n",
              "         [9.96187031e-01, 3.55201564e-03, 2.60923203e-04],\n",
              "         [9.94267046e-01, 5.20009315e-03, 5.32936596e-04],\n",
              "         [9.98957992e-01, 9.21283732e-04, 1.20748897e-04],\n",
              "         [9.98963594e-01, 9.19635117e-04, 1.16777301e-04],\n",
              "         [9.94871259e-01, 4.77636745e-03, 3.52344301e-04],\n",
              "         [9.92532551e-01, 6.92349765e-03, 5.44037437e-04],\n",
              "         [9.94569838e-01, 4.95819980e-03, 4.71973879e-04],\n",
              "         [9.98663902e-01, 1.20707951e-03, 1.29073000e-04],\n",
              "         [9.97741580e-01, 2.10796879e-03, 1.50471955e-04],\n",
              "         [9.95123923e-01, 4.60237823e-03, 2.73693877e-04],\n",
              "         [9.98261988e-01, 1.58725481e-03, 1.50823776e-04],\n",
              "         [9.98117447e-01, 1.66510267e-03, 2.17488472e-04],\n",
              "         [9.98956561e-01, 9.41986626e-04, 1.01515136e-04],\n",
              "         [9.94731545e-01, 4.65001678e-03, 6.18365128e-04],\n",
              "         [8.65644813e-01, 1.27655372e-01, 6.69975672e-03],\n",
              "         [9.98962879e-01, 9.61940445e-04, 7.51710177e-05],\n",
              "         [9.99106348e-01, 8.36298510e-04, 5.72500976e-05],\n",
              "         [9.98937190e-01, 9.87627311e-04, 7.51964762e-05],\n",
              "         [9.96844649e-01, 2.94215581e-03, 2.13187697e-04],\n",
              "         [9.94291425e-01, 5.16543631e-03, 5.43111411e-04]]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ1phPKisJMz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}